{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Messy Notebook where I try to analyze data from Zotero\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, global variables and Zotero session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyzotero.zotero.Zotero object at 0x0000029FCBF331F0>\n"
     ]
    }
   ],
   "source": [
    "from pyzotero import zotero\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "\n",
    "group_library_id = \"5602981\"\n",
    "user_library_id = \"8968938\"  # From: https://www.zotero.org/settings/keys\n",
    "library_type = \"group\"  # To access the shared library, otherwise for private \"user\"\n",
    "api_key = \"jTbkXBSx7Yv0GyOQU3its5Gb\"\n",
    "\n",
    "# Quick ANSI color code shortcurts\n",
    "r = \"\\033[31m\"\n",
    "y = \"\\033[33m\"\n",
    "g = \"\\033[32m\"\n",
    "b = \"\\033[34m\"\n",
    "e = \"\\033[0m\"\n",
    "\n",
    "# Paths to save tmp Dataframes\n",
    "path_to_dataframes = Path(\"..\") / \"data\" / \"Review_ML-RS-FPGA\" / \"Dataframes\"\n",
    "all_articles_df_pkl = (\n",
    "    path_to_dataframes\n",
    "    / f\"all_articles_{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.pkl\"\n",
    ")\n",
    "models_df_pkl = (\n",
    "    path_to_dataframes\n",
    "    / f\"all_datapoints_{datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.pkl\"\n",
    ")\n",
    "\n",
    "zot = zotero.Zotero(group_library_id, library_type, api_key)\n",
    "print(zot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Quick lambda functions ---\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "get_total_in_dict_of_lists = lambda d: sum([len(d[tag]) for tag in d])\n",
    "get_total_in_dict = lambda d: sum([d[tag] for tag in d])\n",
    "\n",
    "\n",
    "# Transforms a dictionnary in a string format (with several lines with \"<key>: <value>\") in a Python dictionnary\n",
    "def parse_string_to_dict(input_string):\n",
    "    # Initialize an empty dictionary\n",
    "    result_dict = {}\n",
    "\n",
    "    # Split the input string by newlines\n",
    "    lines = input_string.split(\"\\n\")\n",
    "\n",
    "    # Iterate over each line\n",
    "    for line in lines:\n",
    "        # Split each line by the first occurrence of ': '\n",
    "        if \": \" in line:\n",
    "            key, value = line.split(\": \", 1)\n",
    "            result_dict[key.strip()] = value.strip()\n",
    "\n",
    "    return result_dict\n",
    "\n",
    "\n",
    "# From get every Zotero items from a library and a list of items' keys\n",
    "def fetch_articles_data(zot: zotero.Zotero, keys: list[str]):\n",
    "    # Prepare a list to hold each article's data\n",
    "    articles_data = []\n",
    "    print(f\"{y}Fetching data for {len(keys)} articles...{e}\")\n",
    "\n",
    "    for key in tqdm(keys):\n",
    "        # Fetch the item data for each key\n",
    "        data = zot.item(key)[\"data\"]\n",
    "\n",
    "        # Extract the relevant information\n",
    "        title = data.get(\"title\", \"\")\n",
    "        doi = data.get(\"DOI\", \"\")\n",
    "        url = data.get(\"url\", \"\")\n",
    "        abstract_note = data.get(\"abstractNote\", \"\")\n",
    "        date = data.get(\"date\", \"\")\n",
    "        item_type = data.get(\"itemType\", \"\")\n",
    "        extra = parse_string_to_dict(data.get(\"extra\", \"\"))\n",
    "\n",
    "        # print(f\" - {g}{title}{e}...\")\n",
    "\n",
    "        # Extract the list of authors\n",
    "        authors = [\n",
    "            f\"{author['firstName']} {author['lastName']}\"\n",
    "            for author in data.get(\"creators\", [])\n",
    "            if author[\"creatorType\"] == \"author\"\n",
    "        ]\n",
    "\n",
    "        # Extract the list of tags\n",
    "        tags = [tag[\"tag\"] for tag in data.get(\"tags\", [])]\n",
    "\n",
    "        # Append the data to the articles_data list\n",
    "        articles_data.append(\n",
    "            {\n",
    "                \"BBT Citation Key\": extra[\"Citation Key\"],\n",
    "                \"Title\": title,\n",
    "                \"Authors\": authors,\n",
    "                \"DOI\": doi,\n",
    "                \"URL\": url,\n",
    "                \"Tags\": tags,\n",
    "                \"Abstract Note\": abstract_note,\n",
    "                \"Date\": date,\n",
    "                \"Item Type\": item_type,\n",
    "                \"Zotero Key\": key,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Create a DataFrame from the collected data\n",
    "    df = pd.DataFrame(articles_data)\n",
    "    df.set_index(\"BBT Citation Key\", inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ---------------------------------- Article analysis ---------------------------------- #\n",
    "\n",
    "\n",
    "# From the list of tags of an item, return 4 lists for each \"Dataset\", \"Model\", \"Board\" and \"Task\"\n",
    "# I use it to detect if an item compares several models, possibly on several board/dataset/or even task\n",
    "def parse_tags(tag_list):\n",
    "    # Initialize a dictionary to hold the parsed information\n",
    "    parsed_data = {\n",
    "        \"Board\": [],\n",
    "        \"Implementation\": [],\n",
    "        \"Models\": [],\n",
    "        \"Datasets\": [],\n",
    "        \"Tasks\": [],\n",
    "    }\n",
    "\n",
    "    # Iterate over each tag in the list\n",
    "    for tag in tag_list:\n",
    "        if tag.startswith(\"Dataset:\"):\n",
    "            parsed_data[\"Datasets\"].append(tag.split(\"Dataset: \")[1].strip())\n",
    "        elif tag.startswith(\"Model:\") and tag != \"Model: N/A\":\n",
    "            parsed_data[\"Models\"].append(tag.split(\"Model: \")[1].strip())\n",
    "        elif tag.startswith(\"Board:\"):\n",
    "            parsed_data[\"Board\"].append(tag.split(\"Board: \")[1].strip())\n",
    "        elif tag.startswith(\"Task:\"):\n",
    "            parsed_data[\"Tasks\"].append(tag.split(\"Task: \")[1].strip())\n",
    "        elif tag.startswith(\"Implementation:\"):\n",
    "            parsed_data[\"Implementation\"].append(\n",
    "                tag.split(\"Implementation: \")[1].strip()\n",
    "            )\n",
    "\n",
    "    if len(parsed_data[\"Implementation\"]) > 1:\n",
    "        print(f\"    Warning: Multiple Implementations detected for {b}{tag_list}{e}\")\n",
    "    if len(parsed_data[\"Board\"]) > 1:\n",
    "        print(f\"    Warning: Multiple Boards detected for {b}{tag_list}{e}\")\n",
    "    return parsed_data\n",
    "\n",
    "\n",
    "# The tags for the model name contain a lot of information A typical model_name is:\n",
    "#  \"<name used in the article> (<corresponding model>) {<backbone>}\", each component is returned in a tuple\n",
    "def parse_model_name(model_name: str) -> tuple[str, str, str] | Literal[-1]:\n",
    "    # Initialize the components\n",
    "    name_used_in_article = None\n",
    "    corresponding_model = \"\"\n",
    "    backbone = \"\"\n",
    "\n",
    "    # Find the positions of the parentheses and curly braces\n",
    "    paren_start: int = model_name.find(\"(\")\n",
    "    paren_end: int = model_name.find(\")\")\n",
    "    brace_start: int = model_name.find(\"{\")\n",
    "    brace_end: int = model_name.find(\"}\")\n",
    "\n",
    "    # If any of the parentheses or curly braces are missing, leave the function\n",
    "    if (paren_start == -1 and paren_end != -1) or (\n",
    "        paren_start != -1 and paren_end == -1\n",
    "    ):\n",
    "        print(\n",
    "            f\"    Warning: {b}{model_name}{e} is not in the expected format for the model name. Parentheses are missing.\"\n",
    "        )\n",
    "        return -1\n",
    "\n",
    "    # Extract the name used in the article\n",
    "    name_used_in_article: str = model_name[:paren_start].strip()\n",
    "    # Extract the corresponding model and the backbone\n",
    "    corresponding_model: str = model_name[paren_start + 1 : paren_end].strip()\n",
    "    if corresponding_model == \"\":\n",
    "        corresponding_model = name_used_in_article\n",
    "    backbone: str = model_name[brace_start + 1 : brace_end].strip()\n",
    "\n",
    "    return name_used_in_article, corresponding_model, backbone\n",
    "\n",
    "\n",
    "# Extract all the systematically reported performance metric (latency, task score (aka, performance), model size, throuput and power)\n",
    "# from <item> which is the row of the Dataframe. If a metric is missing, it gets printed\n",
    "# Choice has been made to set the 'N/A' value to a blank space ' ' (for clarity when printing)\n",
    "def extract_metrics_from_df_row(item, model_name=\"\"):\n",
    "    # print(f'model_name: \"{b}{model_name}{e}\"')\n",
    "    if model_name != \"\":\n",
    "        # Parse the model_name in the 3 components, e.g., A typical model_name is \"<name used in the article> (<corresponding model>) {<backbone>}\"\n",
    "        # Each model_name contains at least the field with the brackets {} and the field without anything, the parenthesis field is bonus\n",
    "        # Example \"Improved YOLOv4-tiny 3L (YOLOv4-tiny) {Darkent53-tiny}\"\n",
    "        model_name, corresponding_model, backbone = parse_model_name(model_name)\n",
    "\n",
    "    # List of possible metrics to look for\n",
    "    metrics_keys = [\n",
    "        \"Model latency: \",  # in ms or FPS\n",
    "        \"Model performance: \",  # in % Acc, $ mIoU, etc.\n",
    "        \"Model size: \",  # in MB\n",
    "        \"Model throughput: \",  # in OP/s\n",
    "        \"Power consumption: \",  # in W\n",
    "    ]\n",
    "\n",
    "    # Initialize an empty dictionary to store the found metrics\n",
    "    metrics_dict = {}\n",
    "    missing_metrics = []\n",
    "\n",
    "    # Iterate through each metric key to ensure all are checked\n",
    "    for key in metrics_keys:\n",
    "        found = False\n",
    "        for tag in item[\"Tags\"]:\n",
    "\n",
    "            # Check for the no-parenthesis syntax (Case 1, 3 or 4)\n",
    "            if tag.startswith(key) and model_name == \"\":\n",
    "                metric_value = tag.split(key)[1].strip()\n",
    "                metric_value = \"\" if metric_value.startswith(\"N/A\") else metric_value\n",
    "                metrics_dict[key[:-2]] = metric_value\n",
    "                found = True\n",
    "                break\n",
    "\n",
    "            # Check for the parenthesis syntax (Case 2, 5 or 6)\n",
    "            # The name within the parenthesis is either the model_name (used in the article) or the backbone\n",
    "            elif tag.startswith(f\"{key}(\") and model_name != \"\":\n",
    "                model_name_in_tag = tag[len(key) :].split(\")\")[0][1:].strip()\n",
    "                if model_name_in_tag == model_name or model_name_in_tag == backbone:\n",
    "                    # print(\n",
    "                    #     f\"model_name_in_tag: {b}{model_name_in_tag}{e} and model_name: {r}{model_name}{e} and backbone: {r}{backbone}{e}\"\n",
    "                    # )\n",
    "                    metric_value = tag.split(\")\")[1].strip()\n",
    "                    metrics_dict[key[:-2]] = metric_value\n",
    "                    found = True\n",
    "                    break\n",
    "\n",
    "        # print(f\"{g}{key}{e}\")\n",
    "        if found and key == \"Model performance: \":\n",
    "            print(f\"{key[:-2]} for {b}{model_name}{e}: {g}{metrics_dict[key[:-2]]}{e}\")\n",
    "            if \"Acc\" in metrics_dict[key[:-2]]:\n",
    "                print(f\"identified Acc/OA metric, replacing it by OA\")\n",
    "                metrics_dict[key[:-2]] = metrics_dict[key[:-2]].replace(\"Acc\", \"OA\")\n",
    "\n",
    "        # If the metric was not found, set its value to '' and print a message\n",
    "        if not found:\n",
    "            metric_name_clean = key[:-2]  # Clean up the metric name for display\n",
    "            metrics_dict[metric_name_clean] = \"\"\n",
    "            missing_metrics.append(metric_name_clean)\n",
    "\n",
    "    # Print missing metrics if any\n",
    "    if missing_metrics:\n",
    "        print(\n",
    "            f\"    Warning: {b}{item['Title']}{e} misses: {r}{', '.join(missing_metrics)}{e} metrics for model {b}{model_name}{e}.\"\n",
    "        )\n",
    "\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Playing with the API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print all collections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collections = zot.all_collections()\n",
    "# print(len(collections), \"collections in your library\")\n",
    "# pprint(collections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get every possible item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Zotero.everything() leverages the 100 items per request limit\n",
    "# all_items = zot.everything(zot.top())\n",
    "# # I have ~310 items and it takes 20s to fetch them all\n",
    "# print(len(all_items), \"items in your library\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See which possible `itemTypes` are available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(len(zot.item_types()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access to the review collection\n",
    "\n",
    "Key for my private user library, the `\"PhD - DLR\"`/`\"On-board AI\"`/`\"Review ML / FPGA / RS\"`/`\"Merge with already read\"` library:\n",
    "\n",
    "- `\"LWR4HAWY\"`\n",
    "\n",
    "Key for the shared library, `\"included in review\"`:\n",
    "\n",
    "- `\"PEWYQYGG\"`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43  items in the review collection\n"
     ]
    }
   ],
   "source": [
    "# Add search paprameters to select only conference papers and journal articles\n",
    "# /!\\ Ideally i just want to NOT select notes and attachments, but I did not find the API syntax to do so\n",
    "zot.add_parameters(itemType=\"conferencePaper || journalArticle\")\n",
    "# Fetch all the items in the library (Without the limitation of 100 items per request)\n",
    "# Key of the group \"included in review\" collection: PEWYQYGG, and key of my private user collection: LWR4HAWY\n",
    "review_items = zot.everything(zot.collection_items(\"PEWYQYGG\"))\n",
    "print(len(review_items), \" items in the review collection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort articles if selected or not\n",
    "\n",
    "All articles in the sub-collection should include the tag \"ML-FPGA Review\" and not have the \"Outside the scope of the review\" or any \"Excluded: \" tag.\n",
    "Nevertheless, double checking doesn't hurt. 🙃\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m0\u001b[0m excluded items + \u001b[32m43\u001b[0m selected for review = \u001b[34m43\u001b[0m total items in the review collection\n",
      "Total number of items excluded: \u001b[31m0\u001b[0m.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "excluded = {}\n",
    "articles_selected_for_review = []\n",
    "# --- For all item ---\n",
    "for item in tqdm(review_items):\n",
    "    # Print the item's title and type\n",
    "    # print(f\"{r}{item['data']['itemType']}{e}\")\n",
    "    # print(f\" - {b}{item['data']['title']}{e}\")\n",
    "\n",
    "    # print(f'Item Type: {item[\"data\"][\"itemType\"]} | Key: {item[\"data\"][\"key\"]}')\n",
    "    # Get the item's tags as a list\n",
    "    tags = item[\"data\"].get(\"tags\", [])\n",
    "    is_excluded = False\n",
    "    for tag in tags:\n",
    "        # Weird but each tag is a dictionary with a \"tag\" key\n",
    "        tag = tag[\"tag\"]\n",
    "        # If the tag starts with \"excluded: \"\n",
    "        if tag.startswith(\"Excluded: \"):\n",
    "            # If the tag is not yet in the excluded dictionary\n",
    "            if tag not in excluded:\n",
    "                # Add the tag as a key and an empty list as the value\n",
    "                excluded[tag] = []\n",
    "\n",
    "            # Add the item's key to the list of keys for the tag\n",
    "            excluded[tag].append(item[\"data\"][\"key\"])\n",
    "            is_excluded = True\n",
    "            break\n",
    "    # If the item is not excluded, add its key to the list of keys for the tag \"Selected for review\"\n",
    "    if not is_excluded:\n",
    "        articles_selected_for_review.append(item[\"data\"][\"key\"])\n",
    "\n",
    "# Verify that the total of excluded items sum up to the total number of items in the review collection\n",
    "total_excluded = 0\n",
    "for key in excluded:\n",
    "    total_excluded += len(excluded[key])\n",
    "\n",
    "print(\n",
    "    f\"{r}{total_excluded}{e} excluded items + {g}{len(articles_selected_for_review)}{e} selected for review = {b}{len(review_items)}{e} total items in the review collection\"\n",
    ")\n",
    "assert total_excluded + len(articles_selected_for_review) == len(review_items)\n",
    "\n",
    "\n",
    "# Print the excluded dictionary\n",
    "print(f\"Total number of items excluded: {r}{total_excluded}{e}.\")\n",
    "for tag, keys in excluded.items():\n",
    "    print(f'{r}{len(keys):>3}{e} items excluded for: {b}\"{tag[10:]}\"{e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the data in a pandas `Dataframe`\n",
    "\n",
    "After verifying that all the articles will be included in the review. Get the actual data of each item, and store it in a Dataframe.\n",
    "\n",
    "Also, save the dataframe, if needed offline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mFetching data for 43 articles...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:33<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe with the original articles saved at: ..\\data\\Review_ML-RS-FPGA\\Dataframes\\all_articles_2024-10-16_09-20-07.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Fetch the data and create a DataFrame\n",
    "selected_articles_df = fetch_articles_data(zot, articles_selected_for_review)\n",
    "# pprint(selected_articles_df)\n",
    "\n",
    "# Write the data (to work offline)\n",
    "selected_articles_df.to_pickle(all_articles_df_pkl)\n",
    "print(f\"Dataframe with the original articles saved at: {all_articles_df_pkl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = all_articles_df_pkl  # .parents[0] / \"all_articles_2024-09-02_11-33-50.pkl\"\n",
    "selected_articles_df = pd.read_pickle(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of articles\n",
    "\n",
    "Each article in the Dataframe has the following fields:\n",
    "\n",
    "```\n",
    "\"BBT Citation Key\", \"Title\", \"Authors\", \"DOI\", \"URL\", \"Tags\", \"Abstract Note\", \"Date\", \"Item Type\", \"Zotero Key\"\n",
    "```\n",
    "\n",
    "Because of the mess (the wide diversity of articles) in the tagging process I have to separate the different cases I can encounter here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Board': ['Zynq US+ (ZU7EV) {ZCU104}'], 'Implementation': ['HLS (Vitis)'], 'Models': ['Deep Belief Network (Diverse) {}'], 'Datasets': ['Airport-Beach-Urban {Pixel classification}'], 'Tasks': ['Pixel classification (Anomaly detection)']}\n",
      "Model performance for \u001b[34m\u001b[0m: \u001b[32m\u001b[0m\n",
      "- (CASE 1) \u001b[34mDeep Belief Network\u001b[0m on \u001b[34mAirport-Beach-Urban {Pixel classification}\u001b[0m with performance: \u001b[31m['5.4 ms', '', '', '', '']\u001b[0m.\n",
      "{'Board': ['Zynq 7000 (Z7020) {PYNQ-Z1}'], 'Implementation': ['HLS (Vivado)'], 'Models': ['CNN () {}'], 'Datasets': ['DAC 2018 {Object Detection}'], 'Tasks': ['Object detection (diverse)']}\n",
      "Model performance for \u001b[34m\u001b[0m: \u001b[32m21% mIoU\u001b[0m\n",
      "- (CASE 1) \u001b[34mCNN\u001b[0m on \u001b[34mDAC 2018 {Object Detection}\u001b[0m with performance: \u001b[31m['7 FPS', '21% mIoU', '', '69.8 GOP/s', '2.38 W']\u001b[0m.\n",
      "{'Board': ['Zynq US+ (ZU3EG) {Ultra96}'], 'Implementation': ['RTL design (N/A)'], 'Models': ['AP2D-Net (CNN) {}'], 'Datasets': ['Custom (UAV) {Object Detection}'], 'Tasks': ['Object detection (diverse)']}\n",
      "Model performance for \u001b[34m\u001b[0m: \u001b[32m55.0% mIoU\u001b[0m\n",
      "- (CASE 1) \u001b[34mAP2D-Net\u001b[0m on \u001b[34mCustom (UAV) {Object Detection}\u001b[0m with performance: \u001b[31m['30.53 FPS', '55.0% mIoU', '', '130.2 GOP/s', '5.59 W']\u001b[0m.\n",
      "{'Board': ['Zynq US+ (ZU7EV) {ZCU104}'], 'Implementation': ['Vitis AI (N/A)'], 'Models': ['RFA-YOLO (YOLOv4 ) {MobileNeXt}'], 'Datasets': ['DIOR {Object Detection}'], 'Tasks': ['Object detection (diverse)']}\n",
      "Model performance for \u001b[34m\u001b[0m: \u001b[32m64.85% mAP\u001b[0m\n",
      "- (CASE 1) \u001b[34mRFA-YOLO\u001b[0m on \u001b[34mDIOR {Object Detection}\u001b[0m with performance: \u001b[31m['27.97 FPS', '64.85% mAP', '24.75 MB', '', '15.82 W']\u001b[0m.\n",
      "{'Board': ['Zynq US+ (ZU9EG) {Quad-FPGA}'], 'Implementation': ['N/A'], 'Models': ['CNN () {}'], 'Datasets': ['Simulated (1-D Signal) {Classification}'], 'Tasks': ['Classification (Redshift estimation [regression])']}\n",
      "Model performance for \u001b[34m\u001b[0m: \u001b[32m\u001b[0m\n",
      "- (CASE 1) \u001b[34mCNN\u001b[0m on \u001b[34mSimulated (1-D Signal) {Classification}\u001b[0m with performance: \u001b[31m['4334 FPS', '', '11 MB', '265 GOP/s', '']\u001b[0m.\n",
      "nerisFPGABasedImplementationCNN2022a: Reports \u001b[31m2\u001b[0m models: \u001b[34m['AlexNetLite (AlexNet) {AlexNet}', 'MobileNetv1Lite (MobileNetv1) {MobileNetv1}']\u001b[0m\n",
      "Model performance for \u001b[34mAlexNetLite\u001b[0m: \u001b[32m89% F1\u001b[0m\n",
      "    Warning: \u001b[34mFPGA-Based Implementation of a CNN Architecture for the On-Board Processing of Very High-Resolution Remote Sensing Images\u001b[0m misses: \u001b[31mModel latency, Model size, Model throughput, Power consumption\u001b[0m metrics for model \u001b[34mAlexNetLite\u001b[0m.\n",
      "    - Model \"\u001b[34mAlexNetLite\u001b[0m\" extracted with performances: \u001b[31m['', '89% F1', '', '', '']\u001b[0m.\n",
      "Model performance for \u001b[34mMobileNetv1Lite\u001b[0m: \u001b[32m94% F1\u001b[0m\n",
      "    Warning: \u001b[34mFPGA-Based Implementation of a CNN Architecture for the On-Board Processing of Very High-Resolution Remote Sensing Images\u001b[0m misses: \u001b[31mModel latency, Model size, Model throughput, Power consumption\u001b[0m metrics for model \u001b[34mMobileNetv1Lite\u001b[0m.\n",
      "    - Model \"\u001b[34mMobileNetv1Lite\u001b[0m\" extracted with performances: \u001b[31m['', '94% F1', '', '', '']\u001b[0m.\n",
      "{'Board': ['Virtex-7 (VX690T) {}'], 'Implementation': ['RTL design (VHDL)'], 'Models': ['SAM-GNN (GNN) {}'], 'Datasets': ['University of Pavia {Pixel classification}'], 'Tasks': ['Pixel classification (Terrain classification)']}\n",
      "Model performance for \u001b[34m\u001b[0m: \u001b[32m95.05% OA\u001b[0m\n",
      "- (CASE 1) \u001b[34mSAM-GNN\u001b[0m on \u001b[34mUniversity of Pavia {Pixel classification}\u001b[0m with performance: \u001b[31m['', '95.05% OA', '', '', '']\u001b[0m.\n",
      "{'Board': ['Zynq 7000 (Z7020) {}'], 'Implementation': ['RTL design (Verilog)'], 'Models': ['Ghost-YOLOS (YOLOv3) {GhostNet}'], 'Datasets': ['DOTAv1.0 {Object Detection}'], 'Tasks': ['Object detection (diverse)']}\n",
      "Model performance for \u001b[34m\u001b[0m: \u001b[32m62.58% mAP\u001b[0m\n",
      "- (CASE 1) \u001b[34mGhost-YOLOS\u001b[0m on \u001b[34mDOTAv1.0 {Object Detection}\u001b[0m with performance: \u001b[31m['3 FPS', '62.58% mAP', '12.6 MB', '29.53 GOP/s', '2.98 W']\u001b[0m.\n",
      "{'Board': ['Zynq US+ (ZU7EV) {ZCU104}'], 'Implementation': ['HLS (N/A)'], 'Models': ['GNN () {}'], 'Datasets': ['MSTAR {Classification}'], 'Tasks': ['Classification (Military targets)']}\n",
      "Model performance for \u001b[34m\u001b[0m: \u001b[32m99.09% Acc\u001b[0m\n",
      "identified Acc/OA metric, replacing it by OA\n",
      "- (CASE 1) \u001b[34mGNN\u001b[0m on \u001b[34mMSTAR {Classification}\u001b[0m with performance: \u001b[31m['0.105 ms', '99.09% OA', '0.96 MB', '', '6.3 W']\u001b[0m.\n",
      "(CASE 7): \u001b[31mwangFastDetectionObstacle2024\u001b[0m nb models = 0 and nb datasets = 1\n",
      "{'Board': ['Zynq US+ (ZU7EV) {ZCU104}'], 'Implementation': ['Vitis AI (1.4)'], 'Models': ['Improved YOLOv4-tiny (YOLOv4-tiny) {CSPDarknet53}'], 'Datasets': ['FastenerDataset {Object Detection}'], 'Tasks': ['Object detection (Railway track fastener defect detection)']}\n",
      "Model performance for \u001b[34m\u001b[0m: \u001b[32m95.1% mAP\u001b[0m\n",
      "- (CASE 1) \u001b[34mImproved YOLOv4-tiny\u001b[0m on \u001b[34mFastenerDataset {Object Detection}\u001b[0m with performance: \u001b[31m['555 FPS', '95.1% mAP', '', '', '20 W']\u001b[0m.\n",
      "{'Board': ['Zynq US+ (ZU7EV) {ZCU104}'], 'Implementation': ['Vitis AI (N/A)'], 'Models': ['YOLOv4-tiny 3L (YOLOv4-tiny) {Darknet53-tiny}'], 'Datasets': ['Custom (UAV) {Object Detection}'], 'Tasks': ['Object detection (Flying-object detection)']}\n",
      "Model performance for \u001b[34m\u001b[0m: \u001b[32m72.24% mAP\u001b[0m\n",
      "- (CASE 1) \u001b[34mYOLOv4-tiny 3L\u001b[0m on \u001b[34mCustom (UAV) {Object Detection}\u001b[0m with performance: \u001b[31m['125 FPS', '72.24% mAP', '24.1 MB', '15.3 GOP/s', '26.4 W']\u001b[0m.\n",
      "{'Board': ['Zynq 7000 (Z7045) {ZC706}'], 'Implementation': ['RTL design (VHDL)'], 'Models': ['CNN () {}'], 'Datasets': ['Kaggle SSI {Classification}'], 'Tasks': ['Classification (Binary ship classification)']}\n",
      "Model performance for \u001b[34m\u001b[0m: \u001b[32m93.44% Acc\u001b[0m\n",
      "identified Acc/OA metric, replacing it by OA\n",
      "- (CASE 1) \u001b[34mCNN\u001b[0m on \u001b[34mKaggle SSI {Classification}\u001b[0m with performance: \u001b[31m['1.01 ms', '93.44% OA', '', '', '1.9 W']\u001b[0m.\n",
      "{'Board': ['Virtex-7 (VX690T) {}'], 'Implementation': ['RTL design (N/A)'], 'Models': ['A2NN (VGG11) {VGG11}'], 'Datasets': ['UC-Merced Land Use {Classification}'], 'Tasks': ['Classification (Terrain type)']}\n",
      "Model performance for \u001b[34m\u001b[0m: \u001b[32m94.76% Prec\u001b[0m\n",
      "- (CASE 1) \u001b[34mA2NN\u001b[0m on \u001b[34mUC-Merced Land Use {Classification}\u001b[0m with performance: \u001b[31m['203 FPS', '94.76% Prec', '', '3047 GOP/s', '8.27 W']\u001b[0m.\n",
      "yangAlgorithmHardwareCodesign2022: Reports \u001b[31m3\u001b[0m models: \u001b[34m['CNN1@1.6 (YOLOv2) {MobileNetv1}', 'CNN3@1.6 (YOLOv2) {MobileNetv2}', 'CNN6@1.6 (YOLOv2) {SqueezeNet}']\u001b[0m\n",
      "Model performance for \u001b[34mCNN1@1.6\u001b[0m: \u001b[32m94% AP\u001b[0m\n",
      "    - Model \"\u001b[34mCNN1@1.6\u001b[0m\" extracted with performances: \u001b[31m['385 FPS', '94% AP', '0.51 MB', '221 GOP/s', '4.8 W']\u001b[0m.\n",
      "Model performance for \u001b[34mCNN3@1.6\u001b[0m: \u001b[32m93.3% AP\u001b[0m\n",
      "    - Model \"\u001b[34mCNN3@1.6\u001b[0m\" extracted with performances: \u001b[31m['380 FPS', '93.3% AP', '0.13 MB', '214 GOP/s', '4.5 W']\u001b[0m.\n",
      "Model performance for \u001b[34mCNN6@1.6\u001b[0m: \u001b[32m92.8% AP\u001b[0m\n",
      "    Warning: \u001b[34mAlgorithm/Hardware Codesign for Real-Time On-Satellite CNN-Based Ship Detection in SAR Imagery\u001b[0m misses: \u001b[31mModel latency\u001b[0m metrics for model \u001b[34mCNN6@1.6\u001b[0m.\n",
      "    - Model \"\u001b[34mCNN6@1.6\u001b[0m\" extracted with performances: \u001b[31m['', '92.8% AP', '0.27 MB', '235 GOP/s', '5.1 W']\u001b[0m.\n",
      "pitonakCloudSatNet1FPGABasedHardwareAccelerated2022: Reports \u001b[31m2\u001b[0m models: \u001b[34m['CloudSatNet-1 Q2 (CNN) {}', 'CloudSatNet-1 Q4 (CNN) {}']\u001b[0m\n",
      "Model performance for \u001b[34mCloudSatNet-1 Q2\u001b[0m: \u001b[32m83.41% Acc\u001b[0m\n",
      "identified Acc/OA metric, replacing it by OA\n",
      "    Warning: \u001b[34mCloudSatNet-1: FPGA-Based Hardware-Accelerated Quantized CNN for Satellite On-Board Cloud Coverage Classification\u001b[0m misses: \u001b[31mModel throughput\u001b[0m metrics for model \u001b[34mCloudSatNet-1 Q2\u001b[0m.\n",
      "    - Model \"\u001b[34mCloudSatNet-1 Q2\u001b[0m\" extracted with performances: \u001b[31m['15.46 FPS', '83.41% OA', '1.43 MB', '', '2.55 W']\u001b[0m.\n",
      "Model performance for \u001b[34mCloudSatNet-1 Q4\u001b[0m: \u001b[32m87.42% Acc\u001b[0m\n",
      "identified Acc/OA metric, replacing it by OA\n",
      "    Warning: \u001b[34mCloudSatNet-1: FPGA-Based Hardware-Accelerated Quantized CNN for Satellite On-Board Cloud Coverage Classification\u001b[0m misses: \u001b[31mModel throughput\u001b[0m metrics for model \u001b[34mCloudSatNet-1 Q4\u001b[0m.\n",
      "    - Model \"\u001b[34mCloudSatNet-1 Q4\u001b[0m\" extracted with performances: \u001b[31m['15.47 FPS', '87.42% OA', '3.06 MB', '', '2.55 W']\u001b[0m.\n",
      "gyaneshwarRealtimeSCSUP2022: Reports \u001b[31m2\u001b[0m models: \u001b[34m['CAL-SC2S (Diverse) {}', 'SVM () {}']\u001b[0m\n",
      "Model performance for \u001b[34mCAL-SC2S\u001b[0m: \u001b[32m29.69% OA\u001b[0m\n",
      "    Warning: \u001b[34mA real-time SC¡SUP¿2¡/SUP¿S-based open-set recognition in remote sensing imagery\u001b[0m misses: \u001b[31mModel size, Model throughput\u001b[0m metrics for model \u001b[34mCAL-SC2S\u001b[0m.\n",
      "    - Model \"\u001b[34mCAL-SC2S\u001b[0m\" extracted with performances: \u001b[31m['2410 ms', '29.69% OA', '', '', '0.358 W']\u001b[0m.\n",
      "Model performance for \u001b[34mSVM\u001b[0m: \u001b[32m20.71% OA\u001b[0m\n",
      "    Warning: \u001b[34mA real-time SC¡SUP¿2¡/SUP¿S-based open-set recognition in remote sensing imagery\u001b[0m misses: \u001b[31mModel size, Model throughput\u001b[0m metrics for model \u001b[34mSVM\u001b[0m.\n",
      "    - Model \"\u001b[34mSVM\u001b[0m\" extracted with performances: \u001b[31m['2160 ms', '20.71% OA', '', '', '0.224 W']\u001b[0m.\n",
      "suhAlgorithmHardwareCoOptimizationEnergyEfficient2021: Reports \u001b[31m3\u001b[0m models: \u001b[34m['SSD 0.25x (SSD300-HW) {VGG16}', 'SSD 0.5x (SSD300-HW) {VGG16}', 'SSD 1.0x (SSD300-HW) {VGG16}']\u001b[0m\n",
      "Model performance for \u001b[34mSSD 0.25x\u001b[0m: \u001b[32m76.2% mAP\u001b[0m\n",
      "    Warning: \u001b[34mAlgorithm-Hardware Co-Optimization for Energy-Efficient Drone Detection on Resource-Constrained FPGA\u001b[0m misses: \u001b[31mModel size\u001b[0m metrics for model \u001b[34mSSD 0.25x\u001b[0m.\n",
      "    - Model \"\u001b[34mSSD 0.25x\u001b[0m\" extracted with performances: \u001b[31m['34.18 FPS', '76.2% mAP', '', '138 GOP/s', '2.4 W']\u001b[0m.\n",
      "Model performance for \u001b[34mSSD 0.5x\u001b[0m: \u001b[32m83.9% mAP\u001b[0m\n",
      "    Warning: \u001b[34mAlgorithm-Hardware Co-Optimization for Energy-Efficient Drone Detection on Resource-Constrained FPGA\u001b[0m misses: \u001b[31mModel size\u001b[0m metrics for model \u001b[34mSSD 0.5x\u001b[0m.\n",
      "    - Model \"\u001b[34mSSD 0.5x\u001b[0m\" extracted with performances: \u001b[31m['9.6 FPS', '83.9% mAP', '', '150 GOP/s', '2.6 W']\u001b[0m.\n",
      "Model performance for \u001b[34mSSD 1.0x\u001b[0m: \u001b[32m88.4% mAP\u001b[0m\n",
      "    Warning: \u001b[34mAlgorithm-Hardware Co-Optimization for Energy-Efficient Drone Detection on Resource-Constrained FPGA\u001b[0m misses: \u001b[31mModel size\u001b[0m metrics for model \u001b[34mSSD 1.0x\u001b[0m.\n",
      "    - Model \"\u001b[34mSSD 1.0x\u001b[0m\" extracted with performances: \u001b[31m['2.56 FPS', '88.4% mAP', '', '158 GOP/s', '2.0 W']\u001b[0m.\n",
      "{'Board': ['Virtex-6 (VLX240T) {}'], 'Implementation': ['RTL design (Verilog)'], 'Models': ['Roller Dung Bettle Clustering (Diverse) {}'], 'Datasets': ['Custom (Landsat-8-OLI) {Segmentation}'], 'Tasks': ['Segmentation (clustering)']}\n",
      "Model performance for \u001b[34m\u001b[0m: \u001b[32m37.45% SSIM\u001b[0m\n",
      "- (CASE 1) \u001b[34mRoller Dung Bettle Clustering\u001b[0m on \u001b[34mCustom (Landsat-8-OLI) {Segmentation}\u001b[0m with performance: \u001b[31m['109670 ms', '37.45% SSIM', '', '', '0.1155 W']\u001b[0m.\n",
      "{'Board': ['Zynq US+ (ZU7EV) {ZCU106}'], 'Implementation': ['RTL design (VHDL)'], 'Models': ['CloudScout (CNN) {}'], 'Datasets': ['Custom (Sentinel-2) {Classification}'], 'Tasks': ['Classification (Binary cloud coverage)']}\n",
      "Model performance for \u001b[34m\u001b[0m: \u001b[32m92.0% Acc\u001b[0m\n",
      "identified Acc/OA metric, replacing it by OA\n",
      "- (CASE 1) \u001b[34mCloudScout\u001b[0m on \u001b[34mCustom (Sentinel-2) {Classification}\u001b[0m with performance: \u001b[31m['141.7 ms', '92.0% OA', '13.3 MB', '', '3.4 W']\u001b[0m.\n",
      "{'Board': ['Zynq 7000 (Z7020) {}'], 'Implementation': ['N/A'], 'Models': ['Weightless Neural Systems (Diverse) {}'], 'Datasets': ['Custom (UAV) {Pixel classification}'], 'Tasks': ['Pixel classification (Deforestation monitoring)']}\n",
      "Model performance for \u001b[34m\u001b[0m: \u001b[32m90.0% Acc\u001b[0m\n",
      "identified Acc/OA metric, replacing it by OA\n",
      "- (CASE 1) \u001b[34mWeightless Neural Systems\u001b[0m on \u001b[34mCustom (UAV) {Pixel classification}\u001b[0m with performance: \u001b[31m['', '90.0% OA', '', '', '']\u001b[0m.\n",
      "{'Board': ['Zynq 7000 (Z7045) {ZC706}'], 'Implementation': ['HLS (FINN)'], 'Models': ['BNN (CNN) {}'], 'Datasets': ['Custom (ALOS-2) {Classification}'], 'Tasks': ['Classification (Ship classification)']}\n",
      "Model performance for \u001b[34m\u001b[0m: \u001b[32m\u001b[0m\n",
      "- (CASE 1) \u001b[34mBNN\u001b[0m on \u001b[34mCustom (ALOS-2) {Classification}\u001b[0m with performance: \u001b[31m['21.14 ms', '', '', '', '']\u001b[0m.\n",
      "{'Board': ['Kintex-7 (XC7K325T) {KC705}'], 'Implementation': ['RTL design (N/A)'], 'Models': ['Modified LeNet-5 (LeNet-5) {LeNet-5}'], 'Datasets': ['MSTAR {Classification}'], 'Tasks': ['Classification (Military targets)']}\n",
      "Model performance for \u001b[34m\u001b[0m: \u001b[32m97.77% Acc\u001b[0m\n",
      "identified Acc/OA metric, replacing it by OA\n",
      "- (CASE 1) \u001b[34mModified LeNet-5\u001b[0m on \u001b[34mMSTAR {Classification}\u001b[0m with performance: \u001b[31m['2.29 ms', '97.77% OA', '1.66 MB', '', '']\u001b[0m.\n",
      "{'Board': ['Spartan-3A (XC3SD1800A) {Avnet Spartan-3A DSP}'], 'Implementation': ['RTL design (VHDL)'], 'Models': ['MLP (MLP) {}'], 'Datasets': ['Custom (UAV) {Classification}'], 'Tasks': ['Classification (Terrain type)']}\n",
      "Model performance for \u001b[34m\u001b[0m: \u001b[32m95.14% Acc\u001b[0m\n",
      "identified Acc/OA metric, replacing it by OA\n",
      "- (CASE 1) \u001b[34mMLP\u001b[0m on \u001b[34mCustom (UAV) {Classification}\u001b[0m with performance: \u001b[31m['', '95.14% OA', '', '', '']\u001b[0m.\n",
      "{'Board': ['Zynq 7000 (Z7100) {}'], 'Implementation': ['RTL design (Verilog)'], 'Models': ['CBFF-SSD (SSD) {MobileNetv1}'], 'Datasets': ['NWPU VHR-10 {Object Detection}'], 'Tasks': ['Object detection (diverse)']}\n",
      "Model performance for \u001b[34m\u001b[0m: \u001b[32m91.42 mAP\u001b[0m\n",
      "- (CASE 1) \u001b[34mCBFF-SSD\u001b[0m on \u001b[34mNWPU VHR-10 {Object Detection}\u001b[0m with performance: \u001b[31m['42.59 ms', '91.42 mAP', '', '452.8 GOP/s', '19.52 W']\u001b[0m.\n",
      "{'Board': ['Zynq 7000 (Z7020) {PYNQ-Z1}'], 'Implementation': ['HLS (FINN)'], 'Models': ['CNN () {}'], 'Datasets': ['Custom (ALOS-2) {Classification}'], 'Tasks': ['Classification (Binary ship classification)']}\n",
      "Model performance for \u001b[34m\u001b[0m: \u001b[32m100% Acc\u001b[0m\n",
      "identified Acc/OA metric, replacing it by OA\n",
      "- (CASE 1) \u001b[34mCNN\u001b[0m on \u001b[34mCustom (ALOS-2) {Classification}\u001b[0m with performance: \u001b[31m['330 ms', '100% OA', '', '', '']\u001b[0m.\n",
      "{'Board': ['Cyclone V (5CSXC6) {}'], 'Implementation': ['HLS (VGT)'], 'Models': ['C-FCN++ (CNN) {}'], 'Datasets': ['38-Cloud {Segmentation}'], 'Tasks': ['Segmentation (cloud extraction)']}\n",
      "Model performance for \u001b[34m\u001b[0m: \u001b[32m79.30% mIoU\u001b[0m\n",
      "- (CASE 1) \u001b[34mC-FCN++\u001b[0m on \u001b[34m38-Cloud {Segmentation}\u001b[0m with performance: \u001b[31m['150 ms', '79.30% mIoU', '0.047 MB', '', '']\u001b[0m.\n",
      "{'Board': ['Zynq 7000 (Z7020) {Arty Z7}'], 'Implementation': ['RTL design (Verilog)'], 'Models': ['Decision Tree (Diverse) {}'], 'Datasets': ['Custom (UAV) {Pixel classification}'], 'Tasks': ['Pixel classification (Safe landing site detection)']}\n",
      "Model performance for \u001b[34m\u001b[0m: \u001b[32m92.1% Acc\u001b[0m\n",
      "identified Acc/OA metric, replacing it by OA\n",
      "- (CASE 1) \u001b[34mDecision Tree\u001b[0m on \u001b[34mCustom (UAV) {Pixel classification}\u001b[0m with performance: \u001b[31m['300 ms', '92.1% OA', '', '', '3.5 W']\u001b[0m.\n",
      "{'Board': ['Virtex-6 (VLX240T) {}'], 'Implementation': ['RTL design (VHDL)'], 'Models': ['Fuzzy ARTMAP (Diverse) {}'], 'Datasets': ['Custom (ALSAT-2A) {Pixel classification}'], 'Tasks': ['Pixel classification (Terrain classification)']}\n",
      "Model performance for \u001b[34m\u001b[0m: \u001b[32m94.8% OA\u001b[0m\n",
      "- (CASE 1) \u001b[34mFuzzy ARTMAP\u001b[0m on \u001b[34mCustom (ALSAT-2A) {Pixel classification}\u001b[0m with performance: \u001b[31m['96 FPS', '94.8% OA', '', '', '0.15 W']\u001b[0m.\n",
      "{'Board': ['Zynq 7000 (Z7020) {PYNQ-Z1}'], 'Implementation': ['N/A'], 'Models': ['MLP (MLP) {}'], 'Datasets': ['Simulated (SAR) {Regression}'], 'Tasks': ['Regression (oil spills feature extraction)']}\n",
      "Model performance for \u001b[34m\u001b[0m: \u001b[32m\u001b[0m\n",
      "- (CASE 1) \u001b[34mMLP\u001b[0m on \u001b[34mSimulated (SAR) {Regression}\u001b[0m with performance: \u001b[31m['', '', '', '', '0.084 W']\u001b[0m.\n",
      "{'Board': ['Zynq US+ (ZU9EG) {}'], 'Implementation': ['HLS (N/A)'], 'Models': ['Improved YOLOv3 (YOLOv3) {DarkNet53}'], 'Datasets': ['Simulated (RGB) {Object Detection}'], 'Tasks': ['Object detection (Aircraft)']}\n",
      "Model performance for \u001b[34m\u001b[0m: \u001b[32m92% Acc\u001b[0m\n",
      "identified Acc/OA metric, replacing it by OA\n",
      "- (CASE 1) \u001b[34mImproved YOLOv3\u001b[0m on \u001b[34mSimulated (RGB) {Object Detection}\u001b[0m with performance: \u001b[31m['7 ms', '92% OA', '8.5 MB', '', '']\u001b[0m.\n",
      "        \u001b[32mResNet-34\u001b[0m, ResNet-34 () {ResNet-34}\n",
      "Model performance for \u001b[34mResNet-34\u001b[0m: \u001b[32m92.81% OA\u001b[0m\n",
      "    - Model \"\u001b[34mResNet-34\u001b[0m\" extracted with performances: \u001b[31m['40.2 ms', '92.81% OA', '21.29 MB', '182 GOP/s', '14.97 W']\u001b[0m.\n",
      "        \u001b[32mVGG16\u001b[0m, VGG16 () {VGG16}\n",
      "Model performance for \u001b[34mVGG16\u001b[0m: \u001b[32m91.90% OA\u001b[0m\n",
      "    - Model \"\u001b[34mVGG16\u001b[0m\" extracted with performances: \u001b[31m['89.1 ms', '91.90% OA', '14.7 MB', '344 GOP/s', '14.97 W']\u001b[0m.\n",
      "        \u001b[32mYOLOv2\u001b[0m, YOLOv2 () {Darknet19}\n",
      "Model performance for \u001b[34mYOLOv2\u001b[0m: \u001b[32m67.30% mAP\u001b[0m\n",
      "    - Model \"\u001b[34mYOLOv2\u001b[0m\" extracted with performances: \u001b[31m['981.4 ms', '67.30% mAP', '49.4 MB', '387 GOP/s', '14.97 W']\u001b[0m.\n",
      "{'Board': ['Zynq US+ (ZU9EG) {Kria KV260}'], 'Implementation': ['Vitis AI (2.5)'], 'Models': ['YOLOv4-MobileNetv3 (YOLOv4) {MobileNetv3}'], 'Datasets': ['DIOR {Object Detection}'], 'Tasks': ['Object detection (diverse)']}\n",
      "Model performance for \u001b[34m\u001b[0m: \u001b[32m82.61% mAP\u001b[0m\n",
      "- (CASE 1) \u001b[34mYOLOv4-MobileNetv3\u001b[0m on \u001b[34mDIOR {Object Detection}\u001b[0m with performance: \u001b[31m['48.14 FPS', '82.61% mAP', '5.69 MB', '', '7.2 W']\u001b[0m.\n",
      "heConfigurable2D3D2023a: Reports \u001b[31m3\u001b[0m models: \u001b[34m['2D CNN (CNN) {}', '3D CNN (CNN) {}', 'HybridSN (CNN) {}']\u001b[0m\n",
      "Model performance for \u001b[34m2D CNN\u001b[0m: \u001b[32m98.24% Acc\u001b[0m\n",
      "identified Acc/OA metric, replacing it by OA\n",
      "    - Model \"\u001b[34m2D CNN\u001b[0m\" extracted with performances: \u001b[31m['0.097 ms', '98.24% OA', '1.2 MB', '7.07 GOP/s', '8.4 W']\u001b[0m.\n",
      "Model performance for \u001b[34m3D CNN\u001b[0m: \u001b[32m94.09% Acc\u001b[0m\n",
      "identified Acc/OA metric, replacing it by OA\n",
      "    - Model \"\u001b[34m3D CNN\u001b[0m\" extracted with performances: \u001b[31m['1.11 ms', '94.09% OA', '0.12 MB', '3.808 GOP/s', '8.4 W']\u001b[0m.\n",
      "Model performance for \u001b[34mHybridSN\u001b[0m: \u001b[32m100% Acc\u001b[0m\n",
      "identified Acc/OA metric, replacing it by OA\n",
      "    - Model \"\u001b[34mHybridSN\u001b[0m\" extracted with performances: \u001b[31m['7.71 ms', '100% OA', '20.5 MB', '13.18 GOP/s', '8.4 W']\u001b[0m.\n",
      "{'Board': ['Virtex-7 (VX690T) {}'], 'Implementation': ['RTL design (VHDL)'], 'Models': ['LPDBL (Diverse) {}'], 'Datasets': ['University of Pavia {Pixel classification}'], 'Tasks': ['Pixel classification (Terrain classification)']}\n",
      "Model performance for \u001b[34m\u001b[0m: \u001b[32m\u001b[0m\n",
      "- (CASE 1) \u001b[34mLPDBL\u001b[0m on \u001b[34mUniversity of Pavia {Pixel classification}\u001b[0m with performance: \u001b[31m['', '', '', '', '']\u001b[0m.\n",
      "{'Board': ['Zynq 7000 (Z7020) {}'], 'Implementation': ['RTL design (VHDL)'], 'Models': ['SVM () {}'], 'Datasets': ['University of Pavia {Pixel classification}'], 'Tasks': ['Pixel classification (Terrain classification)']}\n",
      "Model performance for \u001b[34m\u001b[0m: \u001b[32m82.48% AA\u001b[0m\n",
      "- (CASE 1) \u001b[34mSVM\u001b[0m on \u001b[34mUniversity of Pavia {Pixel classification}\u001b[0m with performance: \u001b[31m['', '82.48% AA', '', '', '']\u001b[0m.\n",
      "sabogalMethodologyEvaluatingAnalyzing2021a: Reports \u001b[31m4\u001b[0m models: \u001b[34m['ENet (Diverse) {}', 'ESPNet (Diverse) {}', 'FPN (Diverse) {}', 'U-Net () {}']\u001b[0m\n",
      "Model performance for \u001b[34mENet\u001b[0m: \u001b[32m63.3% mIoU\u001b[0m\n",
      "    Warning: \u001b[34mA methodology for evaluating and analyzing FPGA-accelerated, deep-learning applications for onboard space processing\u001b[0m misses: \u001b[31mModel throughput\u001b[0m metrics for model \u001b[34mENet\u001b[0m.\n",
      "    - Model \"\u001b[34mENet\u001b[0m\" extracted with performances: \u001b[31m['25.2 FPS', '63.3% mIoU', '0.36 MB', '', '3.36 W']\u001b[0m.\n",
      "Model performance for \u001b[34mESPNet\u001b[0m: \u001b[32m55.5% mIoU\u001b[0m\n",
      "    Warning: \u001b[34mA methodology for evaluating and analyzing FPGA-accelerated, deep-learning applications for onboard space processing\u001b[0m misses: \u001b[31mModel throughput\u001b[0m metrics for model \u001b[34mESPNet\u001b[0m.\n",
      "    - Model \"\u001b[34mESPNet\u001b[0m\" extracted with performances: \u001b[31m['11.7 FPS', '55.5% mIoU', '0.33 MB', '', '3.08 W']\u001b[0m.\n",
      "Model performance for \u001b[34mFPN\u001b[0m: \u001b[32m65.3% mIoU\u001b[0m\n",
      "    Warning: \u001b[34mA methodology for evaluating and analyzing FPGA-accelerated, deep-learning applications for onboard space processing\u001b[0m misses: \u001b[31mModel throughput\u001b[0m metrics for model \u001b[34mFPN\u001b[0m.\n",
      "    - Model \"\u001b[34mFPN\u001b[0m\" extracted with performances: \u001b[31m['14.1 FPS', '65.3% mIoU', '5.84 MB', '', '4.03 W']\u001b[0m.\n",
      "Model performance for \u001b[34mU-Net\u001b[0m: \u001b[32m61.4% mIoU\u001b[0m\n",
      "    Warning: \u001b[34mA methodology for evaluating and analyzing FPGA-accelerated, deep-learning applications for onboard space processing\u001b[0m misses: \u001b[31mModel throughput\u001b[0m metrics for model \u001b[34mU-Net\u001b[0m.\n",
      "    - Model \"\u001b[34mU-Net\u001b[0m\" extracted with performances: \u001b[31m['2.7 FPS', '61.4% mIoU', '7.40 MB', '', '3.38 W']\u001b[0m.\n",
      "        \u001b[32mImproved VGG16\u001b[0m, Improved VGG16 (VGG16) {VGG16}\n",
      "Model performance for \u001b[34mImproved VGG16\u001b[0m: \u001b[32m88.08% OA\u001b[0m\n",
      "    - Model \"\u001b[34mImproved VGG16\u001b[0m\" extracted with performances: \u001b[31m['1780 ms', '88.08% OA', '14.8 MB', '40.96 GOP/s', '3.41 W']\u001b[0m.\n",
      "        \u001b[32mImproved YOLOv2\u001b[0m, Improved YOLOv2 (YOLOv2) {Darknet19}\n",
      "Model performance for \u001b[34mImproved YOLOv2\u001b[0m: \u001b[32m67.30% mAP\u001b[0m\n",
      "    - Model \"\u001b[34mImproved YOLOv2\u001b[0m\" extracted with performances: \u001b[31m['17120 ms', '67.30% mAP', '49.4 MB', '379.55 GOP/s', '3.41 W']\u001b[0m.\n",
      "{'Board': ['Zynq 7000 (Z7035) {}'], 'Implementation': ['RTL design (VHDL)'], 'Models': ['Improved YOLOv2 (YOLOv2) {Darknet19}'], 'Datasets': ['DOTAv1.0 {Object Detection}'], 'Tasks': ['Object detection (diverse)']}\n",
      "Model performance for \u001b[34m\u001b[0m: \u001b[32m67.32% mAP\u001b[0m\n",
      "- (CASE 1) \u001b[34mImproved YOLOv2\u001b[0m on \u001b[34mDOTAv1.0 {Object Detection}\u001b[0m with performance: \u001b[31m['3.4s', '67.32% mAP', '', '111.5 GOP/s', '5.96 W']\u001b[0m.\n",
      "{'Board': ['Kintex-7 (XC7K325T) {}'], 'Implementation': ['N/A'], 'Models': ['LeNet-5 () {LeNet-5}'], 'Datasets': ['MSTAR {Classification}'], 'Tasks': ['Classification (Military targets)']}\n",
      "Model performance for \u001b[34m\u001b[0m: \u001b[32m98.18% Acc\u001b[0m\n",
      "identified Acc/OA metric, replacing it by OA\n",
      "- (CASE 1) \u001b[34mLeNet-5\u001b[0m on \u001b[34mMSTAR {Classification}\u001b[0m with performance: \u001b[31m['2.29 ms', '98.18% OA', '', '', '']\u001b[0m.\n",
      "{'Board': ['Alveo U280 {}'], 'Implementation': ['HLS (N/A)'], 'Models': ['GNN () {}'], 'Datasets': ['MSTAR {Classification}'], 'Tasks': ['Classification (Military targets)']}\n",
      "Model performance for \u001b[34m\u001b[0m: \u001b[32m\u001b[0m\n",
      "- (CASE 1) \u001b[34mGNN\u001b[0m on \u001b[34mMSTAR {Classification}\u001b[0m with performance: \u001b[31m['759 FPS', '', '', '400 GOP/s', '38 W']\u001b[0m.\n",
      "{'Board': ['Virtex-7 (VX690T) {VC709}'], 'Implementation': ['RTL design (VHDL)'], 'Models': ['Q-IORN (IORN4) {VGG16}'], 'Datasets': ['NWPU-RESISC45 {Classification}'], 'Tasks': ['Classification (Terrain type)']}\n",
      "Model performance for \u001b[34m\u001b[0m: \u001b[32m88.31% Acc\u001b[0m\n",
      "identified Acc/OA metric, replacing it by OA\n",
      "- (CASE 1) \u001b[34mQ-IORN\u001b[0m on \u001b[34mNWPU-RESISC45 {Classification}\u001b[0m with performance: \u001b[31m['6.77 FPS', '88.31% OA', '121.51 MB', '209.6 GOP/s', '6.32 W']\u001b[0m.\n",
      "\u001b[31m{'Case 1': 32, 'Case 2': 7, 'Case 3': 0, 'Case 4': 0, 'Case 5': 1, 'Case 6': 1, 'Case 7': 1}\u001b[0m, Total: 42\n"
     ]
    }
   ],
   "source": [
    "datapoints = []\n",
    "articles_type_count = {  # Debug variable\n",
    "    \"Case 1\": 0,\n",
    "    \"Case 2\": 0,\n",
    "    \"Case 3\": 0,\n",
    "    \"Case 4\": 0,\n",
    "    \"Case 5\": 0,\n",
    "    \"Case 6\": 0,\n",
    "    \"Case 7\": 0,\n",
    "}\n",
    "\n",
    "# For each article\n",
    "for index, row in selected_articles_df.iterrows():\n",
    "    parsed_data = parse_tags(row[\"Tags\"])\n",
    "\n",
    "    # @TODO: I will care about articles with many boards later, atm I just report them\n",
    "    if \"???\" in parsed_data[\"Board\"] or len(parsed_data[\"Board\"]) > 1:\n",
    "        # print(f\"{b}{row['Title']}{e}: {parsed_data}\")\n",
    "        continue\n",
    "\n",
    "    # -------------------------- Case 1 (basic): 1 model, 1 dataset (so 1 task), 1 board --------------------------\n",
    "    if len(parsed_data[\"Models\"]) == 1 and len(parsed_data[\"Datasets\"]) == 1:\n",
    "        model_name, model_equivalent, backbone = parse_model_name(\n",
    "            parsed_data[\"Models\"][0]\n",
    "        )\n",
    "        print(f\"{parsed_data}\")\n",
    "        main_info = {\n",
    "            \"BBT Citation Key\": index,\n",
    "            \"Model\": model_name,\n",
    "            \"Equivalent model\": model_equivalent,\n",
    "            \"Backbone\": backbone,\n",
    "            \"Dataset\": f\"{parsed_data['Datasets'][0]}\",\n",
    "            \"Task\": parsed_data[\"Tasks\"][0].split(\"(\")[0].strip(),\n",
    "            \"Application\": parsed_data[\"Tasks\"][0].split(\"(\")[1][:-1].strip(),\n",
    "            \"Board\": parsed_data[\"Board\"][0],\n",
    "            \"Implementation\": parsed_data[\"Implementation\"][0],\n",
    "        }\n",
    "        performance_metrics = extract_metrics_from_df_row(row, \"\")\n",
    "        datapoints.append(main_info | performance_metrics)\n",
    "        articles_type_count[\"Case 1\"] += 1\n",
    "\n",
    "        print(\n",
    "            f\"- (CASE 1) {b}{model_name}{e} on {b}{main_info['Dataset']}{e} with performance: {r}{list(performance_metrics.values())}{e}.\"\n",
    "        )\n",
    "\n",
    "    # -------------------------- Case 2 (comparison of different architectures): X models, 1 dataset (so 1 task), 1 board --------------------------\n",
    "    elif (\n",
    "        len(parsed_data[\"Models\"]) > 1\n",
    "        and len(parsed_data[\"Datasets\"]) == 1\n",
    "        and \"???\" not in parsed_data[\"Models\"]\n",
    "    ):\n",
    "        print(\n",
    "            f\"{index}: Reports {r}{len(parsed_data['Models'])}{e} models: {b}{parsed_data['Models']}{e}\"\n",
    "        )\n",
    "        for model in parsed_data[\"Models\"]:\n",
    "            model_name, model_equivalent, backbone = parse_model_name(model)\n",
    "            main_info = {\n",
    "                \"BBT Citation Key\": index,  # 'BBT Citation Key'\n",
    "                \"Model\": model_name,\n",
    "                \"Equivalent model\": model_equivalent,\n",
    "                \"Backbone\": backbone,\n",
    "                \"Dataset\": parsed_data[\"Datasets\"][0],\n",
    "                \"Task\": parsed_data[\"Tasks\"][0].split(\"(\")[0].strip(),\n",
    "                \"Application\": parsed_data[\"Tasks\"][0].split(\"(\")[1][:-1].strip(),\n",
    "                \"Board\": parsed_data[\"Board\"][0],\n",
    "                \"Implementation\": parsed_data[\"Implementation\"][0],\n",
    "            }\n",
    "            performance_metrics = extract_metrics_from_df_row(row, model)\n",
    "            print(\n",
    "                f'    - Model \"{b}{model_name}{e}\" extracted with performances: {r}{list(performance_metrics.values())}{e}.'\n",
    "            )\n",
    "\n",
    "            datapoints.append(main_info | performance_metrics)\n",
    "\n",
    "        articles_type_count[\"Case 2\"] += 1\n",
    "\n",
    "    # UNSEEN Case 3: 1 model, Y datasets (same task), 1 board => Some articles test their model\n",
    "    # on different datasets, but I reported only the most common/famous dataset (@TODO ?)\n",
    "    # UNSEEN Case 4, a same model for different tasks doesn't exist, if it happens, I will put several times the model tag\n",
    "\n",
    "    # -------------------------- Case 5 (1 model for each dataset, possibly different tasks): X models, X datasets, 1 board --------------------------\n",
    "    elif (\n",
    "        len(parsed_data[\"Models\"]) > 1\n",
    "        and len(parsed_data[\"Datasets\"]) == len(parsed_data[\"Models\"])\n",
    "        and \"???\" not in parsed_data[\"Models\"]\n",
    "    ):\n",
    "        # Because so far I only have 1 article in this case, I will hardcode it\n",
    "        if index == \"yanAutomaticDeploymentConvolutional2022a\":\n",
    "            for model in parsed_data[\"Models\"]:\n",
    "                model_name, model_equivalent, backbone = parse_model_name(model)\n",
    "                print(f\"        {g}{model_name}{e}, {model}\")\n",
    "                # Manage object detection case (1 model: YOLO):\n",
    "                if \"YOLO\" in model_name:\n",
    "                    main_info = {\n",
    "                        \"BBT Citation Key\": index,\n",
    "                        \"Model\": model_name,\n",
    "                        \"Equivalent model\": model_equivalent,\n",
    "                        \"Backbone\": backbone,\n",
    "                        \"Dataset\": \"DOTAv1.0 {Object Detection}\",\n",
    "                        \"Task\": \"Object detection\",\n",
    "                        \"Application\": \"diverse\",\n",
    "                        \"Board\": parsed_data[\"Board\"][0],\n",
    "                        \"Implementation\": parsed_data[\"Implementation\"][0],\n",
    "                    }\n",
    "                # Manage classification case (1 model: VGG16):\n",
    "                else:\n",
    "                    main_info = {\n",
    "                        \"BBT Citation Key\": index,\n",
    "                        \"Model\": model_name,\n",
    "                        \"Equivalent model\": model_equivalent,\n",
    "                        \"Backbone\": backbone,\n",
    "                        \"Dataset\": \"NWPU-RESISC45 {Classification}\",\n",
    "                        \"Task\": \"Classification\",\n",
    "                        \"Application\": \"Terrain type\",\n",
    "                        \"Board\": parsed_data[\"Board\"][0],\n",
    "                        \"Implementation\": parsed_data[\"Implementation\"][0],\n",
    "                    }\n",
    "                performance_metrics = extract_metrics_from_df_row(row, model)\n",
    "                print(\n",
    "                    f'    - Model \"{b}{model_name}{e}\" extracted with performances: {r}{list(performance_metrics.values())}{e}.'\n",
    "                )\n",
    "                datapoints.append(main_info | performance_metrics)\n",
    "            articles_type_count[\"Case 5\"] += 1\n",
    "        else:\n",
    "            print(f\"MANAGE CASE 5 for {r}{index}{e}\")\n",
    "\n",
    "    # -------------------------- Case 6: X models, Y datasets (several models for a same dataset), 1 board --------------------------\n",
    "    elif (\n",
    "        len(parsed_data[\"Models\"]) > 1\n",
    "        and len(parsed_data[\"Datasets\"]) > 1\n",
    "        and \"???\" not in parsed_data[\"Models\"]\n",
    "    ):\n",
    "        # Because so far I only have 1 article in this case, I will hardcode it\n",
    "        if index == \"niAlgorithmHardwareCoOptimization2023\":\n",
    "            for model in parsed_data[\"Models\"]:\n",
    "                model_name, model_equivalent, backbone = parse_model_name(model)\n",
    "                print(f\"        {g}{model_name}{e}, {model}\")\n",
    "                # Manage object detection case (1 model: YOLO):\n",
    "                if model_name.startswith(\"YOLO\"):\n",
    "                    main_info = {\n",
    "                        \"BBT Citation Key\": index,\n",
    "                        \"Model\": model_name,\n",
    "                        \"Equivalent model\": model_equivalent,\n",
    "                        \"Backbone\": backbone,\n",
    "                        \"Dataset\": \"DOTAv1.0 {Object Detection}\",\n",
    "                        \"Task\": \"Object detection\",\n",
    "                        \"Application\": \"diverse\",\n",
    "                        \"Board\": parsed_data[\"Board\"][0],\n",
    "                        \"Implementation\": parsed_data[\"Implementation\"][0],\n",
    "                    }\n",
    "                # Manage classification case (2 models: VGG16 and ResNet-34):\n",
    "                else:\n",
    "                    main_info = {\n",
    "                        \"BBT Citation Key\": index,\n",
    "                        \"Model\": model_name,\n",
    "                        \"Equivalent model\": model_equivalent,\n",
    "                        \"Backbone\": backbone,\n",
    "                        \"Dataset\": \"NWPU-RESISC45 {Classification}\",\n",
    "                        \"Task\": \"Classification\",\n",
    "                        \"Application\": \"Terrain type\",\n",
    "                        \"Board\": parsed_data[\"Board\"][0],\n",
    "                        \"Implementation\": parsed_data[\"Implementation\"][0],\n",
    "                    }\n",
    "                performance_metrics = extract_metrics_from_df_row(row, model)\n",
    "                print(\n",
    "                    f'    - Model \"{b}{model_name}{e}\" extracted with performances: {r}{list(performance_metrics.values())}{e}.'\n",
    "                )\n",
    "                datapoints.append(main_info | performance_metrics)\n",
    "            articles_type_count[\"Case 6\"] += 1\n",
    "        else:\n",
    "            print(f\"MANAGE CASE 6 for {r}{index}{e}\")\n",
    "\n",
    "    # -------------------------- Case 7: Else case --------------------------\n",
    "    else:\n",
    "        print(\n",
    "            f\"(CASE 7): {r}{index}{e} nb models = {len(parsed_data['Models'])} and nb datasets = {len(parsed_data['Datasets'])}\"\n",
    "        )\n",
    "        articles_type_count[\"Case 7\"] += 1\n",
    "\n",
    "print(f\"{r}{articles_type_count}{e}, Total: {sum(articles_type_count.values())}\")\n",
    "datapoints_df = pd.DataFrame(datapoints)\n",
    "# datapoints_df.set_index([\"BBT Citation Key\", \"Model\"], inplace=True)\n",
    "\n",
    "# print(datapoints_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     BBT Citation Key  \\\n",
      "0                       boyleHighlevelFPGADesign2023a   \n",
      "1     wangAccelerationImplementationConvolutional2019   \n",
      "2                          liNovelCNNBasedAP2DNet2020   \n",
      "3                           liEdgeRealtimeObject2023a   \n",
      "4             pitsisEfficientConvolutionalNeural2019a   \n",
      "5                nerisFPGABasedImplementationCNN2022a   \n",
      "6                nerisFPGABasedImplementationCNN2022a   \n",
      "7                chellaswamyFPGAbasedRemoteTarget2024   \n",
      "8                  yangLightweightDetectionMethod2023   \n",
      "9               zhangAccurateLowlatencyEfficient2022a   \n",
      "10                      yuImprovedLightweightDeep2024   \n",
      "11              nguyenFPGASoCImplementationYOLOv42024   \n",
      "12            ieracitanoExplainableEmbeddedNeural2024   \n",
      "13              zhangExtremelyPipelinedFPGAbased2023a   \n",
      "14                  yangAlgorithmHardwareCodesign2022   \n",
      "15                  yangAlgorithmHardwareCodesign2022   \n",
      "16                  yangAlgorithmHardwareCodesign2022   \n",
      "17  pitonakCloudSatNet1FPGABasedHardwareAccelerate...   \n",
      "18  pitonakCloudSatNet1FPGABasedHardwareAccelerate...   \n",
      "19                        gyaneshwarRealtimeSCSUP2022   \n",
      "20                        gyaneshwarRealtimeSCSUP2022   \n",
      "21  suhAlgorithmHardwareCoOptimizationEnergyEffici...   \n",
      "22  suhAlgorithmHardwareCoOptimizationEnergyEffici...   \n",
      "23  suhAlgorithmHardwareCoOptimizationEnergyEffici...   \n",
      "24                      ratnakumarHighSpeedRoller2021   \n",
      "25           rapuanoFPGAbasedHardwareAccelerator2021a   \n",
      "26                 torresCombinedWeightlessNeural2020   \n",
      "27                    myojinDetectingUncertainBNN2020   \n",
      "28           weiFPGABasedHybridTypeImplementation2019   \n",
      "29          matos-carvalhoStaticDynamicAlgorithms2019   \n",
      "30                    liEfficientObjectDetection2019a   \n",
      "31                hashimotoShipClassificationSAR2019a   \n",
      "32                    bahlLowpowerNeuralNetworks2019a   \n",
      "33                    fraczekEmbeddedVisionSystem2018   \n",
      "34            yahiaouiParallelizationFuzzyARTMAP2017a   \n",
      "35          hammoudArtificialNeuralNetworksBased2022a   \n",
      "36                   wuDesignImplementationRemote2021   \n",
      "37              niAlgorithmHardwareCoOptimization2023   \n",
      "38              niAlgorithmHardwareCoOptimization2023   \n",
      "39              niAlgorithmHardwareCoOptimization2023   \n",
      "40             zhaoHardwareAccelerationSatellite2023a   \n",
      "41                            heConfigurable2D3D2023a   \n",
      "42                            heConfigurable2D3D2023a   \n",
      "43                            heConfigurable2D3D2023a   \n",
      "44                   shibiOnboardTargetDetection2021a   \n",
      "45                martinsRealtimeSVMbasedHardware2024   \n",
      "46         sabogalMethodologyEvaluatingAnalyzing2021a   \n",
      "47         sabogalMethodologyEvaluatingAnalyzing2021a   \n",
      "48         sabogalMethodologyEvaluatingAnalyzing2021a   \n",
      "49         sabogalMethodologyEvaluatingAnalyzing2021a   \n",
      "50           yanAutomaticDeploymentConvolutional2022a   \n",
      "51           yanAutomaticDeploymentConvolutional2022a   \n",
      "52               zhangFPGAImplementationCNNbased2021a   \n",
      "53        chenHardwareImplementationConvolutional2020   \n",
      "54                   zhangAcceleratingGNNbasedSAR2023   \n",
      "55          zhangEfficientFPGABasedImplementation2020   \n",
      "\n",
      "                            Model Equivalent model        Backbone  \\\n",
      "0             Deep Belief Network          Diverse                   \n",
      "1                             CNN              CNN                   \n",
      "2                        AP2D-Net              CNN                   \n",
      "3                        RFA-YOLO           YOLOv4      MobileNeXt   \n",
      "4                             CNN              CNN                   \n",
      "5                     AlexNetLite          AlexNet         AlexNet   \n",
      "6                 MobileNetv1Lite      MobileNetv1     MobileNetv1   \n",
      "7                         SAM-GNN              GNN                   \n",
      "8                     Ghost-YOLOS           YOLOv3        GhostNet   \n",
      "9                             GNN              GNN                   \n",
      "10           Improved YOLOv4-tiny      YOLOv4-tiny    CSPDarknet53   \n",
      "11                 YOLOv4-tiny 3L      YOLOv4-tiny  Darknet53-tiny   \n",
      "12                            CNN              CNN                   \n",
      "13                           A2NN            VGG11           VGG11   \n",
      "14                       CNN1@1.6           YOLOv2     MobileNetv1   \n",
      "15                       CNN3@1.6           YOLOv2     MobileNetv2   \n",
      "16                       CNN6@1.6           YOLOv2      SqueezeNet   \n",
      "17               CloudSatNet-1 Q2              CNN                   \n",
      "18               CloudSatNet-1 Q4              CNN                   \n",
      "19                       CAL-SC2S          Diverse                   \n",
      "20                            SVM              SVM                   \n",
      "21                      SSD 0.25x        SSD300-HW           VGG16   \n",
      "22                       SSD 0.5x        SSD300-HW           VGG16   \n",
      "23                       SSD 1.0x        SSD300-HW           VGG16   \n",
      "24  Roller Dung Bettle Clustering          Diverse                   \n",
      "25                     CloudScout              CNN                   \n",
      "26      Weightless Neural Systems          Diverse                   \n",
      "27                            BNN              CNN                   \n",
      "28               Modified LeNet-5          LeNet-5         LeNet-5   \n",
      "29                            MLP              MLP                   \n",
      "30                       CBFF-SSD              SSD     MobileNetv1   \n",
      "31                            CNN              CNN                   \n",
      "32                        C-FCN++              CNN                   \n",
      "33                  Decision Tree          Diverse                   \n",
      "34                   Fuzzy ARTMAP          Diverse                   \n",
      "35                            MLP              MLP                   \n",
      "36                Improved YOLOv3           YOLOv3       DarkNet53   \n",
      "37                      ResNet-34        ResNet-34       ResNet-34   \n",
      "38                          VGG16            VGG16           VGG16   \n",
      "39                         YOLOv2           YOLOv2       Darknet19   \n",
      "40             YOLOv4-MobileNetv3           YOLOv4     MobileNetv3   \n",
      "41                         2D CNN              CNN                   \n",
      "42                         3D CNN              CNN                   \n",
      "43                       HybridSN              CNN                   \n",
      "44                          LPDBL          Diverse                   \n",
      "45                            SVM              SVM                   \n",
      "46                           ENet          Diverse                   \n",
      "47                         ESPNet          Diverse                   \n",
      "48                            FPN          Diverse                   \n",
      "49                          U-Net            U-Net                   \n",
      "50                 Improved VGG16            VGG16           VGG16   \n",
      "51                Improved YOLOv2           YOLOv2       Darknet19   \n",
      "52                Improved YOLOv2           YOLOv2       Darknet19   \n",
      "53                        LeNet-5          LeNet-5         LeNet-5   \n",
      "54                            GNN              GNN                   \n",
      "55                         Q-IORN            IORN4           VGG16   \n",
      "\n",
      "                                       Dataset                  Task  \\\n",
      "0   Airport-Beach-Urban {Pixel classification}  Pixel classification   \n",
      "1                  DAC 2018 {Object Detection}      Object detection   \n",
      "2              Custom (UAV) {Object Detection}      Object detection   \n",
      "3                      DIOR {Object Detection}      Object detection   \n",
      "4      Simulated (1-D Signal) {Classification}        Classification   \n",
      "5                      MASATI {Classification}        Classification   \n",
      "6                      MASATI {Classification}        Classification   \n",
      "7   University of Pavia {Pixel classification}  Pixel classification   \n",
      "8                  DOTAv1.0 {Object Detection}      Object detection   \n",
      "9                       MSTAR {Classification}        Classification   \n",
      "10          FastenerDataset {Object Detection}      Object detection   \n",
      "11             Custom (UAV) {Object Detection}      Object detection   \n",
      "12                 Kaggle SSI {Classification}        Classification   \n",
      "13         UC-Merced Land Use {Classification}        Classification   \n",
      "14                     SSDD {Object Detection}      Object detection   \n",
      "15                     SSDD {Object Detection}      Object detection   \n",
      "16                     SSDD {Object Detection}      Object detection   \n",
      "17                   L8 Biome {Classification}        Classification   \n",
      "18                   L8 Biome {Classification}        Classification   \n",
      "19            AVIRIS-NG {Pixel classification}  Pixel classification   \n",
      "20            AVIRIS-NG {Pixel classification}  Pixel classification   \n",
      "21     Multi-drone (custom) {Object Detection}      Object detection   \n",
      "22     Multi-drone (custom) {Object Detection}      Object detection   \n",
      "23     Multi-drone (custom) {Object Detection}      Object detection   \n",
      "24       Custom (Landsat-8-OLI) {Segmentation}          Segmentation   \n",
      "25        Custom (Sentinel-2) {Classification}        Classification   \n",
      "26         Custom (UAV) {Pixel classification}  Pixel classification   \n",
      "27            Custom (ALOS-2) {Classification}        Classification   \n",
      "28                      MSTAR {Classification}        Classification   \n",
      "29               Custom (UAV) {Classification}        Classification   \n",
      "30              NWPU VHR-10 {Object Detection}      Object detection   \n",
      "31            Custom (ALOS-2) {Classification}        Classification   \n",
      "32                     38-Cloud {Segmentation}          Segmentation   \n",
      "33         Custom (UAV) {Pixel classification}  Pixel classification   \n",
      "34    Custom (ALSAT-2A) {Pixel classification}  Pixel classification   \n",
      "35                Simulated (SAR) {Regression}            Regression   \n",
      "36          Simulated (RGB) {Object Detection}      Object detection   \n",
      "37              NWPU-RESISC45 {Classification}        Classification   \n",
      "38              NWPU-RESISC45 {Classification}        Classification   \n",
      "39                 DOTAv1.0 {Object Detection}      Object detection   \n",
      "40                     DIOR {Object Detection}      Object detection   \n",
      "41  University of Pavia {Pixel classification}  Pixel classification   \n",
      "42  University of Pavia {Pixel classification}  Pixel classification   \n",
      "43  University of Pavia {Pixel classification}  Pixel classification   \n",
      "44  University of Pavia {Pixel classification}  Pixel classification   \n",
      "45  University of Pavia {Pixel classification}  Pixel classification   \n",
      "46                      Potsdam {Segmentation}          Segmentation   \n",
      "47                      Potsdam {Segmentation}          Segmentation   \n",
      "48                      Potsdam {Segmentation}          Segmentation   \n",
      "49                      Potsdam {Segmentation}          Segmentation   \n",
      "50              NWPU-RESISC45 {Classification}        Classification   \n",
      "51                 DOTAv1.0 {Object Detection}      Object detection   \n",
      "52                 DOTAv1.0 {Object Detection}      Object detection   \n",
      "53                      MSTAR {Classification}        Classification   \n",
      "54                      MSTAR {Classification}        Classification   \n",
      "55              NWPU-RESISC45 {Classification}        Classification   \n",
      "\n",
      "                                Application  \\\n",
      "0                         Anomaly detection   \n",
      "1                                   diverse   \n",
      "2                                   diverse   \n",
      "3                                   diverse   \n",
      "4          Redshift estimation [regression]   \n",
      "5                   Binary target detection   \n",
      "6                   Binary target detection   \n",
      "7                    Terrain classification   \n",
      "8                                   diverse   \n",
      "9                          Military targets   \n",
      "10  Railway track fastener defect detection   \n",
      "11                  Flying-object detection   \n",
      "12               Binary ship classification   \n",
      "13                             Terrain type   \n",
      "14                           Ship detection   \n",
      "15                           Ship detection   \n",
      "16                           Ship detection   \n",
      "17                    Binary cloud coverage   \n",
      "18                    Binary cloud coverage   \n",
      "19                   Terrain classification   \n",
      "20                   Terrain classification   \n",
      "21                                Drone/UAV   \n",
      "22                                Drone/UAV   \n",
      "23                                Drone/UAV   \n",
      "24                               clustering   \n",
      "25                    Binary cloud coverage   \n",
      "26                 Deforestation monitoring   \n",
      "27                      Ship classification   \n",
      "28                         Military targets   \n",
      "29                             Terrain type   \n",
      "30                                  diverse   \n",
      "31               Binary ship classification   \n",
      "32                         cloud extraction   \n",
      "33              Safe landing site detection   \n",
      "34                   Terrain classification   \n",
      "35            oil spills feature extraction   \n",
      "36                                 Aircraft   \n",
      "37                             Terrain type   \n",
      "38                             Terrain type   \n",
      "39                                  diverse   \n",
      "40                                  diverse   \n",
      "41                   Terrain classification   \n",
      "42                   Terrain classification   \n",
      "43                   Terrain classification   \n",
      "44                   Terrain classification   \n",
      "45                   Terrain classification   \n",
      "46                              Urban areas   \n",
      "47                              Urban areas   \n",
      "48                              Urban areas   \n",
      "49                              Urban areas   \n",
      "50                             Terrain type   \n",
      "51                                  diverse   \n",
      "52                                  diverse   \n",
      "53                         Military targets   \n",
      "54                         Military targets   \n",
      "55                             Terrain type   \n",
      "\n",
      "                                             Board         Implementation  \\\n",
      "0                        Zynq US+ (ZU7EV) {ZCU104}            HLS (Vitis)   \n",
      "1                      Zynq 7000 (Z7020) {PYNQ-Z1}           HLS (Vivado)   \n",
      "2                       Zynq US+ (ZU3EG) {Ultra96}       RTL design (N/A)   \n",
      "3                        Zynq US+ (ZU7EV) {ZCU104}         Vitis AI (N/A)   \n",
      "4                     Zynq US+ (ZU9EG) {Quad-FPGA}                    N/A   \n",
      "5                     Kintex US (XCKU040) {KCU105}            HLS (Vitis)   \n",
      "6                     Kintex US (XCKU040) {KCU105}            HLS (Vitis)   \n",
      "7                             Virtex-7 (VX690T) {}      RTL design (VHDL)   \n",
      "8                             Zynq 7000 (Z7020) {}   RTL design (Verilog)   \n",
      "9                        Zynq US+ (ZU7EV) {ZCU104}              HLS (N/A)   \n",
      "10                       Zynq US+ (ZU7EV) {ZCU104}         Vitis AI (1.4)   \n",
      "11                       Zynq US+ (ZU7EV) {ZCU104}         Vitis AI (N/A)   \n",
      "12                       Zynq 7000 (Z7045) {ZC706}      RTL design (VHDL)   \n",
      "13                            Virtex-7 (VX690T) {}       RTL design (N/A)   \n",
      "14                       Virtex-7 (VX690T) {VC709}            HLS (Vitis)   \n",
      "15                       Virtex-7 (VX690T) {VC709}            HLS (Vitis)   \n",
      "16                       Virtex-7 (VX690T) {VC709}            HLS (Vitis)   \n",
      "17                      Zynq 7000 (Z7020) {Z-turn}             HLS (FINN)   \n",
      "18                      Zynq 7000 (Z7020) {Z-turn}             HLS (FINN)   \n",
      "19                    Artix-7 (XC7A35T) {Arty-35T}       RTL design (XSG)   \n",
      "20                    Artix-7 (XC7A35T) {Arty-35T}       RTL design (XSG)   \n",
      "21                         Zynq US+ (ZU3EG) {OVC3}                    N/A   \n",
      "22                         Zynq US+ (ZU3EG) {OVC3}                    N/A   \n",
      "23                         Zynq US+ (ZU3EG) {OVC3}                    N/A   \n",
      "24                           Virtex-6 (VLX240T) {}   RTL design (Verilog)   \n",
      "25                       Zynq US+ (ZU7EV) {ZCU106}      RTL design (VHDL)   \n",
      "26                            Zynq 7000 (Z7020) {}                    N/A   \n",
      "27                       Zynq 7000 (Z7045) {ZC706}             HLS (FINN)   \n",
      "28                     Kintex-7 (XC7K325T) {KC705}       RTL design (N/A)   \n",
      "29  Spartan-3A (XC3SD1800A) {Avnet Spartan-3A DSP}      RTL design (VHDL)   \n",
      "30                            Zynq 7000 (Z7100) {}   RTL design (Verilog)   \n",
      "31                     Zynq 7000 (Z7020) {PYNQ-Z1}             HLS (FINN)   \n",
      "32                           Cyclone V (5CSXC6) {}              HLS (VGT)   \n",
      "33                     Zynq 7000 (Z7020) {Arty Z7}   RTL design (Verilog)   \n",
      "34                           Virtex-6 (VLX240T) {}      RTL design (VHDL)   \n",
      "35                     Zynq 7000 (Z7020) {PYNQ-Z1}                    N/A   \n",
      "36                             Zynq US+ (ZU9EG) {}              HLS (N/A)   \n",
      "37                       Virtex-7 (VX690T) {VC709}   RTL design (Verilog)   \n",
      "38                       Virtex-7 (VX690T) {VC709}   RTL design (Verilog)   \n",
      "39                       Virtex-7 (VX690T) {VC709}   RTL design (Verilog)   \n",
      "40                   Zynq US+ (ZU9EG) {Kria KV260}         Vitis AI (2.5)   \n",
      "41               Zynq US+ (ZU15EG) {Alinx AXU15EG}       RTL design (N/A)   \n",
      "42               Zynq US+ (ZU15EG) {Alinx AXU15EG}       RTL design (N/A)   \n",
      "43               Zynq US+ (ZU15EG) {Alinx AXU15EG}       RTL design (N/A)   \n",
      "44                            Virtex-7 (VX690T) {}      RTL design (VHDL)   \n",
      "45                            Zynq 7000 (Z7020) {}      RTL design (VHDL)   \n",
      "46                  Zynq US+ (ZU3EG) {UltraZed-EG}  Vitis AI (DNNDK v3.1)   \n",
      "47                  Zynq US+ (ZU3EG) {UltraZed-EG}  Vitis AI (DNNDK v3.1)   \n",
      "48                  Zynq US+ (ZU3EG) {UltraZed-EG}  Vitis AI (DNNDK v3.1)   \n",
      "49                  Zynq US+ (ZU3EG) {UltraZed-EG}  Vitis AI (DNNDK v3.1)   \n",
      "50                      Artix-7 (XC7A200T) (AC701)      RTL design (VHDL)   \n",
      "51                      Artix-7 (XC7A200T) (AC701)      RTL design (VHDL)   \n",
      "52                            Zynq 7000 (Z7035) {}      RTL design (VHDL)   \n",
      "53                          Kintex-7 (XC7K325T) {}                    N/A   \n",
      "54                                   Alveo U280 {}              HLS (N/A)   \n",
      "55                       Virtex-7 (VX690T) {VC709}      RTL design (VHDL)   \n",
      "\n",
      "   Model latency Model performance Model size Model throughput  \\\n",
      "0         5.4 ms                                                 \n",
      "1          7 FPS          21% mIoU                  69.8 GOP/s   \n",
      "2      30.53 FPS        55.0% mIoU                 130.2 GOP/s   \n",
      "3      27.97 FPS        64.85% mAP   24.75 MB                    \n",
      "4       4334 FPS                        11 MB        265 GOP/s   \n",
      "5                           89% F1                               \n",
      "6                           94% F1                               \n",
      "7                        95.05% OA                               \n",
      "8          3 FPS        62.58% mAP    12.6 MB      29.53 GOP/s   \n",
      "9       0.105 ms         99.09% OA    0.96 MB                    \n",
      "10       555 FPS         95.1% mAP                               \n",
      "11       125 FPS        72.24% mAP    24.1 MB       15.3 GOP/s   \n",
      "12       1.01 ms         93.44% OA                               \n",
      "13       203 FPS       94.76% Prec                  3047 GOP/s   \n",
      "14       385 FPS            94% AP    0.51 MB        221 GOP/s   \n",
      "15       380 FPS          93.3% AP    0.13 MB        214 GOP/s   \n",
      "16                        92.8% AP    0.27 MB        235 GOP/s   \n",
      "17     15.46 FPS         83.41% OA    1.43 MB                    \n",
      "18     15.47 FPS         87.42% OA    3.06 MB                    \n",
      "19       2410 ms         29.69% OA                               \n",
      "20       2160 ms         20.71% OA                               \n",
      "21     34.18 FPS         76.2% mAP                   138 GOP/s   \n",
      "22       9.6 FPS         83.9% mAP                   150 GOP/s   \n",
      "23      2.56 FPS         88.4% mAP                   158 GOP/s   \n",
      "24     109670 ms       37.45% SSIM                               \n",
      "25      141.7 ms          92.0% OA    13.3 MB                    \n",
      "26                        90.0% OA                               \n",
      "27      21.14 ms                                                 \n",
      "28       2.29 ms         97.77% OA    1.66 MB                    \n",
      "29                       95.14% OA                               \n",
      "30      42.59 ms         91.42 mAP                 452.8 GOP/s   \n",
      "31        330 ms           100% OA                               \n",
      "32        150 ms       79.30% mIoU   0.047 MB                    \n",
      "33        300 ms          92.1% OA                               \n",
      "34        96 FPS          94.8% OA                               \n",
      "35                                                               \n",
      "36          7 ms            92% OA     8.5 MB                    \n",
      "37       40.2 ms         92.81% OA   21.29 MB        182 GOP/s   \n",
      "38       89.1 ms         91.90% OA    14.7 MB        344 GOP/s   \n",
      "39      981.4 ms        67.30% mAP    49.4 MB        387 GOP/s   \n",
      "40     48.14 FPS        82.61% mAP    5.69 MB                    \n",
      "41      0.097 ms         98.24% OA     1.2 MB       7.07 GOP/s   \n",
      "42       1.11 ms         94.09% OA    0.12 MB      3.808 GOP/s   \n",
      "43       7.71 ms           100% OA    20.5 MB      13.18 GOP/s   \n",
      "44                                                               \n",
      "45                       82.48% AA                               \n",
      "46      25.2 FPS        63.3% mIoU    0.36 MB                    \n",
      "47      11.7 FPS        55.5% mIoU    0.33 MB                    \n",
      "48      14.1 FPS        65.3% mIoU    5.84 MB                    \n",
      "49       2.7 FPS        61.4% mIoU    7.40 MB                    \n",
      "50       1780 ms         88.08% OA    14.8 MB      40.96 GOP/s   \n",
      "51      17120 ms        67.30% mAP    49.4 MB     379.55 GOP/s   \n",
      "52          3.4s        67.32% mAP                 111.5 GOP/s   \n",
      "53       2.29 ms         98.18% OA                               \n",
      "54       759 FPS                                     400 GOP/s   \n",
      "55      6.77 FPS         88.31% OA  121.51 MB      209.6 GOP/s   \n",
      "\n",
      "   Power consumption  \n",
      "0                     \n",
      "1             2.38 W  \n",
      "2             5.59 W  \n",
      "3            15.82 W  \n",
      "4                     \n",
      "5                     \n",
      "6                     \n",
      "7                     \n",
      "8             2.98 W  \n",
      "9              6.3 W  \n",
      "10              20 W  \n",
      "11            26.4 W  \n",
      "12             1.9 W  \n",
      "13            8.27 W  \n",
      "14             4.8 W  \n",
      "15             4.5 W  \n",
      "16             5.1 W  \n",
      "17            2.55 W  \n",
      "18            2.55 W  \n",
      "19           0.358 W  \n",
      "20           0.224 W  \n",
      "21             2.4 W  \n",
      "22             2.6 W  \n",
      "23             2.0 W  \n",
      "24          0.1155 W  \n",
      "25             3.4 W  \n",
      "26                    \n",
      "27                    \n",
      "28                    \n",
      "29                    \n",
      "30           19.52 W  \n",
      "31                    \n",
      "32                    \n",
      "33             3.5 W  \n",
      "34            0.15 W  \n",
      "35           0.084 W  \n",
      "36                    \n",
      "37           14.97 W  \n",
      "38           14.97 W  \n",
      "39           14.97 W  \n",
      "40             7.2 W  \n",
      "41             8.4 W  \n",
      "42             8.4 W  \n",
      "43             8.4 W  \n",
      "44                    \n",
      "45                    \n",
      "46            3.36 W  \n",
      "47            3.08 W  \n",
      "48            4.03 W  \n",
      "49            3.38 W  \n",
      "50            3.41 W  \n",
      "51            3.41 W  \n",
      "52            5.96 W  \n",
      "53                    \n",
      "54              38 W  \n",
      "55            6.32 W  \n"
     ]
    }
   ],
   "source": [
    "print(datapoints_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoints_df.to_pickle(models_df_pkl)\n",
    "# datapoints_df = pd.read_pickle(name_models_df_pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the number of missing metrics per paper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             BBT Citation Key  Missing metrics\n",
      "0               boyleHighlevelFPGADesign2023a                4\n",
      "5        nerisFPGABasedImplementationCNN2022a                4\n",
      "6        nerisFPGABasedImplementationCNN2022a                4\n",
      "7        chellaswamyFPGAbasedRemoteTarget2024                4\n",
      "26         torresCombinedWeightlessNeural2020                4\n",
      "27            myojinDetectingUncertainBNN2020                4\n",
      "29  matos-carvalhoStaticDynamicAlgorithms2019                4\n",
      "35  hammoudArtificialNeuralNetworksBased2022a                4\n",
      "44           shibiOnboardTargetDetection2021a                5\n",
      "45        martinsRealtimeSVMbasedHardware2024                4\n",
      "\u001b[31m9\u001b[0m models miss the \u001b[34mModel latency\u001b[0m metric.\n",
      "\u001b[31m6\u001b[0m models miss the \u001b[34mModel performance\u001b[0m metric.\n",
      "\u001b[31m28\u001b[0m models miss the \u001b[34mModel size\u001b[0m metric.\n",
      "\u001b[31m32\u001b[0m models miss the \u001b[34mModel throughput\u001b[0m metric.\n",
      "\u001b[31m15\u001b[0m models miss the \u001b[34mPower consumption\u001b[0m metric.\n"
     ]
    }
   ],
   "source": [
    "def is_undefined(str) -> bool:\n",
    "    return str.startswith(\"N/A\") or str.startswith(\"???\") or str == \"\"\n",
    "\n",
    "\n",
    "# --- # Quick check if any of the main information is missing ---\n",
    "for index, row in datapoints_df.iterrows():\n",
    "\n",
    "    if is_undefined(row[\"Model\"]):\n",
    "        print(f\"Item N°{b}{index}{e} has no Model\")\n",
    "    if is_undefined(row[\"Dataset\"]):\n",
    "        print(f\"Item N°{b}{index}{e} has no Dataset\")\n",
    "    if is_undefined(row[\"Board\"]):\n",
    "        print(f\"Item N°{b}{index}{e} has no Board\")\n",
    "    if is_undefined(row[\"Task\"]):\n",
    "        print(f\"Item N°{b}{index}{e} has no Task\")\n",
    "\n",
    "# --- Compute the number of missing (performance) metrics for each model ---\n",
    "# Add a column to the dataframe with the number of missing metrics\n",
    "datapoints_df[\"Missing metrics\"] = datapoints_df.apply(\n",
    "    lambda row: sum(\n",
    "        [\n",
    "            is_undefined(row[metric])\n",
    "            for metric in [\n",
    "                \"Model latency\",\n",
    "                \"Model performance\",\n",
    "                \"Model size\",\n",
    "                \"Model throughput\",\n",
    "                \"Power consumption\",\n",
    "            ]\n",
    "        ]\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "# Print only the 'BBT Citation Key' and the missing metrics, only if there is more than 3 missing metrics\n",
    "print(\n",
    "    datapoints_df[datapoints_df[\"Missing metrics\"] >= 4][\n",
    "        [\"BBT Citation Key\", \"Missing metrics\"]\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# --- Print the most missing metrics (for each metric) ---\n",
    "for metric in [\n",
    "    \"Model latency\",\n",
    "    \"Model performance\",\n",
    "    \"Model size\",\n",
    "    \"Model throughput\",\n",
    "    \"Power consumption\",\n",
    "]:\n",
    "    missing_metrics = 0\n",
    "    for index, row in datapoints_df.iterrows():\n",
    "        if is_undefined(row[metric]):\n",
    "            missing_metrics += 1\n",
    "\n",
    "    # Print the number of models missing the metric\n",
    "    print(f\"{r}{missing_metrics}{e} models miss the {b}{metric}{e} metric.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze common dataset\n",
    "\n",
    "Check how many models (and paper) use the same datasets\n",
    "\n",
    "About the mean of implementation on FPGA:\n",
    "\n",
    "- 20 RTL design: 10 VHDL, 5 Verilog, 1 XSG (@TODO: what is that?) and 4 N/A\n",
    "- 11 HLS: 3 Vitis, 1 Vivado, 3 FINN, 1 VGT (@TODO: classify with Vitis AI?) and 3 N/A\n",
    "- 5 Vitis AI\n",
    "- 6 N/A + 1 ??? (the review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset\n",
      "University of Pavia {Pixel classification}    6\n",
      "Potsdam {Segmentation}                        4\n",
      "NWPU-RESISC45 {Classification}                4\n",
      "DOTAv1.0 {Object Detection}                   4\n",
      "MSTAR {Classification}                        4\n",
      "SSDD {Object Detection}                       3\n",
      "Multi-drone (custom) {Object Detection}       3\n",
      "Custom (ALOS-2) {Classification}              2\n",
      "Custom (UAV) {Pixel classification}           2\n",
      "L8 Biome {Classification}                     2\n",
      "AVIRIS-NG {Pixel classification}              2\n",
      "DIOR {Object Detection}                       2\n",
      "Custom (UAV) {Object Detection}               2\n",
      "MASATI {Classification}                       2\n",
      "Custom (UAV) {Classification}                 1\n",
      "Simulated (RGB) {Object Detection}            1\n",
      "Simulated (SAR) {Regression}                  1\n",
      "Custom (ALSAT-2A) {Pixel classification}      1\n",
      "38-Cloud {Segmentation}                       1\n",
      "NWPU VHR-10 {Object Detection}                1\n",
      "UC-Merced Land Use {Classification}           1\n",
      "Kaggle SSI {Classification}                   1\n",
      "Simulated (1-D Signal) {Classification}       1\n",
      "Custom (Sentinel-2) {Classification}          1\n",
      "Custom (Landsat-8-OLI) {Segmentation}         1\n",
      "DAC 2018 {Object Detection}                   1\n",
      "FastenerDataset {Object Detection}            1\n",
      "Airport-Beach-Urban {Pixel classification}    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\u001b[34mUniversity of Pavia {Pixel classification}\u001b[0m dataset:\n",
      "    - \u001b[31mSAM-GNN\u001b[0m from \u001b[34mchellaswamyFPGAbasedRemoteTarget2024\u001b[0m with board: \u001b[31mVirtex-7 (VX690T) {}\u001b[0m (\u001b[34mRTL design (VHDL)\u001b[0m):\n",
      "        Score: \u001b[32m95.05% OA\u001b[0m, Size: \u001b[32m\u001b[0m, Latency: \u001b[32m\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m\u001b[0m\n",
      "    - \u001b[31m2D CNN\u001b[0m from \u001b[34mheConfigurable2D3D2023a\u001b[0m with board: \u001b[31mZynq US+ (ZU15EG) {Alinx AXU15EG}\u001b[0m (\u001b[34mRTL design (N/A)\u001b[0m):\n",
      "        Score: \u001b[32m98.24% OA\u001b[0m, Size: \u001b[32m1.2 MB\u001b[0m, Latency: \u001b[32m0.097 ms\u001b[0m, Throughput: \u001b[32m7.07 GOP/s\u001b[0m, Power: \u001b[32m8.4 W\u001b[0m\n",
      "    - \u001b[31m3D CNN\u001b[0m from \u001b[34mheConfigurable2D3D2023a\u001b[0m with board: \u001b[31mZynq US+ (ZU15EG) {Alinx AXU15EG}\u001b[0m (\u001b[34mRTL design (N/A)\u001b[0m):\n",
      "        Score: \u001b[32m94.09% OA\u001b[0m, Size: \u001b[32m0.12 MB\u001b[0m, Latency: \u001b[32m1.11 ms\u001b[0m, Throughput: \u001b[32m3.808 GOP/s\u001b[0m, Power: \u001b[32m8.4 W\u001b[0m\n",
      "    - \u001b[31mHybridSN\u001b[0m from \u001b[34mheConfigurable2D3D2023a\u001b[0m with board: \u001b[31mZynq US+ (ZU15EG) {Alinx AXU15EG}\u001b[0m (\u001b[34mRTL design (N/A)\u001b[0m):\n",
      "        Score: \u001b[32m100% OA\u001b[0m, Size: \u001b[32m20.5 MB\u001b[0m, Latency: \u001b[32m7.71 ms\u001b[0m, Throughput: \u001b[32m13.18 GOP/s\u001b[0m, Power: \u001b[32m8.4 W\u001b[0m\n",
      "    - \u001b[31mLPDBL\u001b[0m from \u001b[34mshibiOnboardTargetDetection2021a\u001b[0m with board: \u001b[31mVirtex-7 (VX690T) {}\u001b[0m (\u001b[34mRTL design (VHDL)\u001b[0m):\n",
      "        Score: \u001b[32m\u001b[0m, Size: \u001b[32m\u001b[0m, Latency: \u001b[32m\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m\u001b[0m\n",
      "    - \u001b[31mSVM\u001b[0m from \u001b[34mmartinsRealtimeSVMbasedHardware2024\u001b[0m with board: \u001b[31mZynq 7000 (Z7020) {}\u001b[0m (\u001b[34mRTL design (VHDL)\u001b[0m):\n",
      "        Score: \u001b[32m82.48% AA\u001b[0m, Size: \u001b[32m\u001b[0m, Latency: \u001b[32m\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m\u001b[0m\n",
      "\n",
      "\u001b[34mPotsdam {Segmentation}\u001b[0m dataset:\n",
      "    - \u001b[31mENet\u001b[0m from \u001b[34msabogalMethodologyEvaluatingAnalyzing2021a\u001b[0m with board: \u001b[31mZynq US+ (ZU3EG) {UltraZed-EG}\u001b[0m (\u001b[34mVitis AI (DNNDK v3.1)\u001b[0m):\n",
      "        Score: \u001b[32m63.3% mIoU\u001b[0m, Size: \u001b[32m0.36 MB\u001b[0m, Latency: \u001b[32m25.2 FPS\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m3.36 W\u001b[0m\n",
      "    - \u001b[31mESPNet\u001b[0m from \u001b[34msabogalMethodologyEvaluatingAnalyzing2021a\u001b[0m with board: \u001b[31mZynq US+ (ZU3EG) {UltraZed-EG}\u001b[0m (\u001b[34mVitis AI (DNNDK v3.1)\u001b[0m):\n",
      "        Score: \u001b[32m55.5% mIoU\u001b[0m, Size: \u001b[32m0.33 MB\u001b[0m, Latency: \u001b[32m11.7 FPS\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m3.08 W\u001b[0m\n",
      "    - \u001b[31mFPN\u001b[0m from \u001b[34msabogalMethodologyEvaluatingAnalyzing2021a\u001b[0m with board: \u001b[31mZynq US+ (ZU3EG) {UltraZed-EG}\u001b[0m (\u001b[34mVitis AI (DNNDK v3.1)\u001b[0m):\n",
      "        Score: \u001b[32m65.3% mIoU\u001b[0m, Size: \u001b[32m5.84 MB\u001b[0m, Latency: \u001b[32m14.1 FPS\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m4.03 W\u001b[0m\n",
      "    - \u001b[31mU-Net\u001b[0m from \u001b[34msabogalMethodologyEvaluatingAnalyzing2021a\u001b[0m with board: \u001b[31mZynq US+ (ZU3EG) {UltraZed-EG}\u001b[0m (\u001b[34mVitis AI (DNNDK v3.1)\u001b[0m):\n",
      "        Score: \u001b[32m61.4% mIoU\u001b[0m, Size: \u001b[32m7.40 MB\u001b[0m, Latency: \u001b[32m2.7 FPS\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m3.38 W\u001b[0m\n",
      "\n",
      "\u001b[34mNWPU-RESISC45 {Classification}\u001b[0m dataset:\n",
      "    - \u001b[31mResNet-34\u001b[0m from \u001b[34mniAlgorithmHardwareCoOptimization2023\u001b[0m with board: \u001b[31mVirtex-7 (VX690T) {VC709}\u001b[0m (\u001b[34mRTL design (Verilog)\u001b[0m):\n",
      "        Score: \u001b[32m92.81% OA\u001b[0m, Size: \u001b[32m21.29 MB\u001b[0m, Latency: \u001b[32m40.2 ms\u001b[0m, Throughput: \u001b[32m182 GOP/s\u001b[0m, Power: \u001b[32m14.97 W\u001b[0m\n",
      "    - \u001b[31mVGG16\u001b[0m from \u001b[34mniAlgorithmHardwareCoOptimization2023\u001b[0m with board: \u001b[31mVirtex-7 (VX690T) {VC709}\u001b[0m (\u001b[34mRTL design (Verilog)\u001b[0m):\n",
      "        Score: \u001b[32m91.90% OA\u001b[0m, Size: \u001b[32m14.7 MB\u001b[0m, Latency: \u001b[32m89.1 ms\u001b[0m, Throughput: \u001b[32m344 GOP/s\u001b[0m, Power: \u001b[32m14.97 W\u001b[0m\n",
      "    - \u001b[31mImproved VGG16\u001b[0m from \u001b[34myanAutomaticDeploymentConvolutional2022a\u001b[0m with board: \u001b[31mArtix-7 (XC7A200T) (AC701)\u001b[0m (\u001b[34mRTL design (VHDL)\u001b[0m):\n",
      "        Score: \u001b[32m88.08% OA\u001b[0m, Size: \u001b[32m14.8 MB\u001b[0m, Latency: \u001b[32m1780 ms\u001b[0m, Throughput: \u001b[32m40.96 GOP/s\u001b[0m, Power: \u001b[32m3.41 W\u001b[0m\n",
      "    - \u001b[31mQ-IORN\u001b[0m from \u001b[34mzhangEfficientFPGABasedImplementation2020\u001b[0m with board: \u001b[31mVirtex-7 (VX690T) {VC709}\u001b[0m (\u001b[34mRTL design (VHDL)\u001b[0m):\n",
      "        Score: \u001b[32m88.31% OA\u001b[0m, Size: \u001b[32m121.51 MB\u001b[0m, Latency: \u001b[32m6.77 FPS\u001b[0m, Throughput: \u001b[32m209.6 GOP/s\u001b[0m, Power: \u001b[32m6.32 W\u001b[0m\n",
      "\n",
      "\u001b[34mDOTAv1.0 {Object Detection}\u001b[0m dataset:\n",
      "    - \u001b[31mGhost-YOLOS\u001b[0m from \u001b[34myangLightweightDetectionMethod2023\u001b[0m with board: \u001b[31mZynq 7000 (Z7020) {}\u001b[0m (\u001b[34mRTL design (Verilog)\u001b[0m):\n",
      "        Score: \u001b[32m62.58% mAP\u001b[0m, Size: \u001b[32m12.6 MB\u001b[0m, Latency: \u001b[32m3 FPS\u001b[0m, Throughput: \u001b[32m29.53 GOP/s\u001b[0m, Power: \u001b[32m2.98 W\u001b[0m\n",
      "    - \u001b[31mYOLOv2\u001b[0m from \u001b[34mniAlgorithmHardwareCoOptimization2023\u001b[0m with board: \u001b[31mVirtex-7 (VX690T) {VC709}\u001b[0m (\u001b[34mRTL design (Verilog)\u001b[0m):\n",
      "        Score: \u001b[32m67.30% mAP\u001b[0m, Size: \u001b[32m49.4 MB\u001b[0m, Latency: \u001b[32m981.4 ms\u001b[0m, Throughput: \u001b[32m387 GOP/s\u001b[0m, Power: \u001b[32m14.97 W\u001b[0m\n",
      "    - \u001b[31mImproved YOLOv2\u001b[0m from \u001b[34myanAutomaticDeploymentConvolutional2022a\u001b[0m with board: \u001b[31mArtix-7 (XC7A200T) (AC701)\u001b[0m (\u001b[34mRTL design (VHDL)\u001b[0m):\n",
      "        Score: \u001b[32m67.30% mAP\u001b[0m, Size: \u001b[32m49.4 MB\u001b[0m, Latency: \u001b[32m17120 ms\u001b[0m, Throughput: \u001b[32m379.55 GOP/s\u001b[0m, Power: \u001b[32m3.41 W\u001b[0m\n",
      "    - \u001b[31mImproved YOLOv2\u001b[0m from \u001b[34mzhangFPGAImplementationCNNbased2021a\u001b[0m with board: \u001b[31mZynq 7000 (Z7035) {}\u001b[0m (\u001b[34mRTL design (VHDL)\u001b[0m):\n",
      "        Score: \u001b[32m67.32% mAP\u001b[0m, Size: \u001b[32m\u001b[0m, Latency: \u001b[32m3.4s\u001b[0m, Throughput: \u001b[32m111.5 GOP/s\u001b[0m, Power: \u001b[32m5.96 W\u001b[0m\n",
      "\n",
      "\u001b[34mMSTAR {Classification}\u001b[0m dataset:\n",
      "    - \u001b[31mGNN\u001b[0m from \u001b[34mzhangAccurateLowlatencyEfficient2022a\u001b[0m with board: \u001b[31mZynq US+ (ZU7EV) {ZCU104}\u001b[0m (\u001b[34mHLS (N/A)\u001b[0m):\n",
      "        Score: \u001b[32m99.09% OA\u001b[0m, Size: \u001b[32m0.96 MB\u001b[0m, Latency: \u001b[32m0.105 ms\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m6.3 W\u001b[0m\n",
      "    - \u001b[31mModified LeNet-5\u001b[0m from \u001b[34mweiFPGABasedHybridTypeImplementation2019\u001b[0m with board: \u001b[31mKintex-7 (XC7K325T) {KC705}\u001b[0m (\u001b[34mRTL design (N/A)\u001b[0m):\n",
      "        Score: \u001b[32m97.77% OA\u001b[0m, Size: \u001b[32m1.66 MB\u001b[0m, Latency: \u001b[32m2.29 ms\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m\u001b[0m\n",
      "    - \u001b[31mLeNet-5\u001b[0m from \u001b[34mchenHardwareImplementationConvolutional2020\u001b[0m with board: \u001b[31mKintex-7 (XC7K325T) {}\u001b[0m (\u001b[34mN/A\u001b[0m):\n",
      "        Score: \u001b[32m98.18% OA\u001b[0m, Size: \u001b[32m\u001b[0m, Latency: \u001b[32m2.29 ms\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m\u001b[0m\n",
      "    - \u001b[31mGNN\u001b[0m from \u001b[34mzhangAcceleratingGNNbasedSAR2023\u001b[0m with board: \u001b[31mAlveo U280 {}\u001b[0m (\u001b[34mHLS (N/A)\u001b[0m):\n",
      "        Score: \u001b[32m\u001b[0m, Size: \u001b[32m\u001b[0m, Latency: \u001b[32m759 FPS\u001b[0m, Throughput: \u001b[32m400 GOP/s\u001b[0m, Power: \u001b[32m38 W\u001b[0m\n",
      "\n",
      "\u001b[34mSSDD {Object Detection}\u001b[0m dataset:\n",
      "    - \u001b[31mCNN1@1.6\u001b[0m from \u001b[34myangAlgorithmHardwareCodesign2022\u001b[0m with board: \u001b[31mVirtex-7 (VX690T) {VC709}\u001b[0m (\u001b[34mHLS (Vitis)\u001b[0m):\n",
      "        Score: \u001b[32m94% AP\u001b[0m, Size: \u001b[32m0.51 MB\u001b[0m, Latency: \u001b[32m385 FPS\u001b[0m, Throughput: \u001b[32m221 GOP/s\u001b[0m, Power: \u001b[32m4.8 W\u001b[0m\n",
      "    - \u001b[31mCNN3@1.6\u001b[0m from \u001b[34myangAlgorithmHardwareCodesign2022\u001b[0m with board: \u001b[31mVirtex-7 (VX690T) {VC709}\u001b[0m (\u001b[34mHLS (Vitis)\u001b[0m):\n",
      "        Score: \u001b[32m93.3% AP\u001b[0m, Size: \u001b[32m0.13 MB\u001b[0m, Latency: \u001b[32m380 FPS\u001b[0m, Throughput: \u001b[32m214 GOP/s\u001b[0m, Power: \u001b[32m4.5 W\u001b[0m\n",
      "    - \u001b[31mCNN6@1.6\u001b[0m from \u001b[34myangAlgorithmHardwareCodesign2022\u001b[0m with board: \u001b[31mVirtex-7 (VX690T) {VC709}\u001b[0m (\u001b[34mHLS (Vitis)\u001b[0m):\n",
      "        Score: \u001b[32m92.8% AP\u001b[0m, Size: \u001b[32m0.27 MB\u001b[0m, Latency: \u001b[32m\u001b[0m, Throughput: \u001b[32m235 GOP/s\u001b[0m, Power: \u001b[32m5.1 W\u001b[0m\n",
      "\n",
      "\u001b[34mMulti-drone (custom) {Object Detection}\u001b[0m dataset:\n",
      "    - \u001b[31mSSD 0.25x\u001b[0m from \u001b[34msuhAlgorithmHardwareCoOptimizationEnergyEfficient2021\u001b[0m with board: \u001b[31mZynq US+ (ZU3EG) {OVC3}\u001b[0m (\u001b[34mN/A\u001b[0m):\n",
      "        Score: \u001b[32m76.2% mAP\u001b[0m, Size: \u001b[32m\u001b[0m, Latency: \u001b[32m34.18 FPS\u001b[0m, Throughput: \u001b[32m138 GOP/s\u001b[0m, Power: \u001b[32m2.4 W\u001b[0m\n",
      "    - \u001b[31mSSD 0.5x\u001b[0m from \u001b[34msuhAlgorithmHardwareCoOptimizationEnergyEfficient2021\u001b[0m with board: \u001b[31mZynq US+ (ZU3EG) {OVC3}\u001b[0m (\u001b[34mN/A\u001b[0m):\n",
      "        Score: \u001b[32m83.9% mAP\u001b[0m, Size: \u001b[32m\u001b[0m, Latency: \u001b[32m9.6 FPS\u001b[0m, Throughput: \u001b[32m150 GOP/s\u001b[0m, Power: \u001b[32m2.6 W\u001b[0m\n",
      "    - \u001b[31mSSD 1.0x\u001b[0m from \u001b[34msuhAlgorithmHardwareCoOptimizationEnergyEfficient2021\u001b[0m with board: \u001b[31mZynq US+ (ZU3EG) {OVC3}\u001b[0m (\u001b[34mN/A\u001b[0m):\n",
      "        Score: \u001b[32m88.4% mAP\u001b[0m, Size: \u001b[32m\u001b[0m, Latency: \u001b[32m2.56 FPS\u001b[0m, Throughput: \u001b[32m158 GOP/s\u001b[0m, Power: \u001b[32m2.0 W\u001b[0m\n",
      "\n",
      "\u001b[34mCustom (ALOS-2) {Classification}\u001b[0m dataset:\n",
      "    - \u001b[31mBNN\u001b[0m from \u001b[34mmyojinDetectingUncertainBNN2020\u001b[0m with board: \u001b[31mZynq 7000 (Z7045) {ZC706}\u001b[0m (\u001b[34mHLS (FINN)\u001b[0m):\n",
      "        Score: \u001b[32m\u001b[0m, Size: \u001b[32m\u001b[0m, Latency: \u001b[32m21.14 ms\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m\u001b[0m\n",
      "    - \u001b[31mCNN\u001b[0m from \u001b[34mhashimotoShipClassificationSAR2019a\u001b[0m with board: \u001b[31mZynq 7000 (Z7020) {PYNQ-Z1}\u001b[0m (\u001b[34mHLS (FINN)\u001b[0m):\n",
      "        Score: \u001b[32m100% OA\u001b[0m, Size: \u001b[32m\u001b[0m, Latency: \u001b[32m330 ms\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dataset_counts = datapoints_df[\"Dataset\"].value_counts()\n",
    "print(dataset_counts)\n",
    "\n",
    "# For the first 4 datasets, print each model's name, the corresponding article research key and their metric\n",
    "for dataset in dataset_counts.index[:8]:\n",
    "    print(f\"\\n{b}{dataset}{e} dataset:\")\n",
    "    for index, row in datapoints_df.iterrows():\n",
    "        if row[\"Dataset\"] == dataset:\n",
    "            print(\n",
    "                f\"    - {r}{row['Model']}{e} from {b}{row['BBT Citation Key']}{e} with board: {r}{row['Board']}{e} ({b}{row['Implementation']}{e}):\"\n",
    "            )\n",
    "            print(\n",
    "                f\"        Score: {g}{row['Model performance']}{e}, Size: {g}{row['Model size']}{e}, Latency: {g}{row['Model latency']}{e}, Throughput: {g}{row['Model throughput']}{e}, Power: {g}{row['Power consumption']}{e}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze common tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task\n",
      "Classification          19\n",
      "Object detection        18\n",
      "Pixel classification    12\n",
      "Segmentation             6\n",
      "Regression               1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\u001b[34mClassification\u001b[0m task (total: 19):\n",
      "    \u001b[34mNWPU-RESISC45\u001b[0m:\n",
      "        - \u001b[31mResNet-34\u001b[0m (ResNet-34) [\u001b[33mResNet-34\u001b[0m] from \u001b[34mniAlgorithmHardwareCoOptimization2023\u001b[0m with board: \u001b[31mVirtex-7 (VX690T) {VC709}\u001b[0m (RTL design (Verilog)):\n",
      "            Score: \u001b[32m92.81% OA\u001b[0m, Size: \u001b[32m21.29 MB\u001b[0m, Latency: \u001b[32m40.2 ms\u001b[0m, Throughput: \u001b[32m182 GOP/s\u001b[0m, Power: \u001b[32m14.97 W\u001b[0m\n",
      "        - \u001b[31mVGG16\u001b[0m (VGG16) [\u001b[33mVGG16\u001b[0m] from \u001b[34mniAlgorithmHardwareCoOptimization2023\u001b[0m with board: \u001b[31mVirtex-7 (VX690T) {VC709}\u001b[0m (RTL design (Verilog)):\n",
      "            Score: \u001b[32m91.90% OA\u001b[0m, Size: \u001b[32m14.7 MB\u001b[0m, Latency: \u001b[32m89.1 ms\u001b[0m, Throughput: \u001b[32m344 GOP/s\u001b[0m, Power: \u001b[32m14.97 W\u001b[0m\n",
      "        - \u001b[31mImproved VGG16\u001b[0m (VGG16) [\u001b[33mVGG16\u001b[0m] from \u001b[34myanAutomaticDeploymentConvolutional2022a\u001b[0m with board: \u001b[31mArtix-7 (XC7A200T) (AC701)\u001b[0m (RTL design (VHDL)):\n",
      "            Score: \u001b[32m88.08% OA\u001b[0m, Size: \u001b[32m14.8 MB\u001b[0m, Latency: \u001b[32m1780 ms\u001b[0m, Throughput: \u001b[32m40.96 GOP/s\u001b[0m, Power: \u001b[32m3.41 W\u001b[0m\n",
      "        - \u001b[31mQ-IORN\u001b[0m (IORN4) [\u001b[33mVGG16\u001b[0m] from \u001b[34mzhangEfficientFPGABasedImplementation2020\u001b[0m with board: \u001b[31mVirtex-7 (VX690T) {VC709}\u001b[0m (RTL design (VHDL)):\n",
      "            Score: \u001b[32m88.31% OA\u001b[0m, Size: \u001b[32m121.51 MB\u001b[0m, Latency: \u001b[32m6.77 FPS\u001b[0m, Throughput: \u001b[32m209.6 GOP/s\u001b[0m, Power: \u001b[32m6.32 W\u001b[0m\n",
      "    \u001b[34mMSTAR\u001b[0m:\n",
      "        - \u001b[31mGNN\u001b[0m (GNN) [\u001b[33m\u001b[0m] from \u001b[34mzhangAccurateLowlatencyEfficient2022a\u001b[0m with board: \u001b[31mZynq US+ (ZU7EV) {ZCU104}\u001b[0m (HLS (N/A)):\n",
      "            Score: \u001b[32m99.09% OA\u001b[0m, Size: \u001b[32m0.96 MB\u001b[0m, Latency: \u001b[32m0.105 ms\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m6.3 W\u001b[0m\n",
      "        - \u001b[31mModified LeNet-5\u001b[0m (LeNet-5) [\u001b[33mLeNet-5\u001b[0m] from \u001b[34mweiFPGABasedHybridTypeImplementation2019\u001b[0m with board: \u001b[31mKintex-7 (XC7K325T) {KC705}\u001b[0m (RTL design (N/A)):\n",
      "            Score: \u001b[32m97.77% OA\u001b[0m, Size: \u001b[32m1.66 MB\u001b[0m, Latency: \u001b[32m2.29 ms\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m\u001b[0m\n",
      "        - \u001b[31mLeNet-5\u001b[0m (LeNet-5) [\u001b[33mLeNet-5\u001b[0m] from \u001b[34mchenHardwareImplementationConvolutional2020\u001b[0m with board: \u001b[31mKintex-7 (XC7K325T) {}\u001b[0m (N/A):\n",
      "            Score: \u001b[32m98.18% OA\u001b[0m, Size: \u001b[32m\u001b[0m, Latency: \u001b[32m2.29 ms\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m\u001b[0m\n",
      "        - \u001b[31mGNN\u001b[0m (GNN) [\u001b[33m\u001b[0m] from \u001b[34mzhangAcceleratingGNNbasedSAR2023\u001b[0m with board: \u001b[31mAlveo U280 {}\u001b[0m (HLS (N/A)):\n",
      "            Score: \u001b[32m\u001b[0m, Size: \u001b[32m\u001b[0m, Latency: \u001b[32m759 FPS\u001b[0m, Throughput: \u001b[32m400 GOP/s\u001b[0m, Power: \u001b[32m38 W\u001b[0m\n",
      "    \u001b[34mCustom (ALOS-2)\u001b[0m:\n",
      "        - \u001b[31mBNN\u001b[0m (CNN) [\u001b[33m\u001b[0m] from \u001b[34mmyojinDetectingUncertainBNN2020\u001b[0m with board: \u001b[31mZynq 7000 (Z7045) {ZC706}\u001b[0m (HLS (FINN)):\n",
      "            Score: \u001b[32m\u001b[0m, Size: \u001b[32m\u001b[0m, Latency: \u001b[32m21.14 ms\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m\u001b[0m\n",
      "        - \u001b[31mCNN\u001b[0m (CNN) [\u001b[33m\u001b[0m] from \u001b[34mhashimotoShipClassificationSAR2019a\u001b[0m with board: \u001b[31mZynq 7000 (Z7020) {PYNQ-Z1}\u001b[0m (HLS (FINN)):\n",
      "            Score: \u001b[32m100% OA\u001b[0m, Size: \u001b[32m\u001b[0m, Latency: \u001b[32m330 ms\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m\u001b[0m\n",
      "    \u001b[34mL8 Biome\u001b[0m:\n",
      "        - \u001b[31mCloudSatNet-1 Q2\u001b[0m (CNN) [\u001b[33m\u001b[0m] from \u001b[34mpitonakCloudSatNet1FPGABasedHardwareAccelerated2022\u001b[0m with board: \u001b[31mZynq 7000 (Z7020) {Z-turn}\u001b[0m (HLS (FINN)):\n",
      "            Score: \u001b[32m83.41% OA\u001b[0m, Size: \u001b[32m1.43 MB\u001b[0m, Latency: \u001b[32m15.46 FPS\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m2.55 W\u001b[0m\n",
      "        - \u001b[31mCloudSatNet-1 Q4\u001b[0m (CNN) [\u001b[33m\u001b[0m] from \u001b[34mpitonakCloudSatNet1FPGABasedHardwareAccelerated2022\u001b[0m with board: \u001b[31mZynq 7000 (Z7020) {Z-turn}\u001b[0m (HLS (FINN)):\n",
      "            Score: \u001b[32m87.42% OA\u001b[0m, Size: \u001b[32m3.06 MB\u001b[0m, Latency: \u001b[32m15.47 FPS\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m2.55 W\u001b[0m\n",
      "    \u001b[34mMASATI\u001b[0m:\n",
      "        - \u001b[31mAlexNetLite\u001b[0m (AlexNet) [\u001b[33mAlexNet\u001b[0m] from \u001b[34mnerisFPGABasedImplementationCNN2022a\u001b[0m with board: \u001b[31mKintex US (XCKU040) {KCU105}\u001b[0m (HLS (Vitis)):\n",
      "            Score: \u001b[32m89% F1\u001b[0m, Size: \u001b[32m\u001b[0m, Latency: \u001b[32m\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m\u001b[0m\n",
      "        - \u001b[31mMobileNetv1Lite\u001b[0m (MobileNetv1) [\u001b[33mMobileNetv1\u001b[0m] from \u001b[34mnerisFPGABasedImplementationCNN2022a\u001b[0m with board: \u001b[31mKintex US (XCKU040) {KCU105}\u001b[0m (HLS (Vitis)):\n",
      "            Score: \u001b[32m94% F1\u001b[0m, Size: \u001b[32m\u001b[0m, Latency: \u001b[32m\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m\u001b[0m\n",
      "    \u001b[34mCustom (UAV)\u001b[0m:\n",
      "        - \u001b[31mMLP\u001b[0m (MLP) [\u001b[33m\u001b[0m] from \u001b[34mmatos-carvalhoStaticDynamicAlgorithms2019\u001b[0m with board: \u001b[31mSpartan-3A (XC3SD1800A) {Avnet Spartan-3A DSP}\u001b[0m (RTL design (VHDL)):\n",
      "            Score: \u001b[32m95.14% OA\u001b[0m, Size: \u001b[32m\u001b[0m, Latency: \u001b[32m\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m\u001b[0m\n",
      "    \u001b[34mUC-Merced Land Use\u001b[0m:\n",
      "        - \u001b[31mA2NN\u001b[0m (VGG11) [\u001b[33mVGG11\u001b[0m] from \u001b[34mzhangExtremelyPipelinedFPGAbased2023a\u001b[0m with board: \u001b[31mVirtex-7 (VX690T) {}\u001b[0m (RTL design (N/A)):\n",
      "            Score: \u001b[32m94.76% Prec\u001b[0m, Size: \u001b[32m\u001b[0m, Latency: \u001b[32m203 FPS\u001b[0m, Throughput: \u001b[32m3047 GOP/s\u001b[0m, Power: \u001b[32m8.27 W\u001b[0m\n",
      "    \u001b[34mKaggle SSI\u001b[0m:\n",
      "        - \u001b[31mCNN\u001b[0m (CNN) [\u001b[33m\u001b[0m] from \u001b[34mieracitanoExplainableEmbeddedNeural2024\u001b[0m with board: \u001b[31mZynq 7000 (Z7045) {ZC706}\u001b[0m (RTL design (VHDL)):\n",
      "            Score: \u001b[32m93.44% OA\u001b[0m, Size: \u001b[32m\u001b[0m, Latency: \u001b[32m1.01 ms\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m1.9 W\u001b[0m\n",
      "    \u001b[34mSimulated (1-D Signal)\u001b[0m:\n",
      "        - \u001b[31mCNN\u001b[0m (CNN) [\u001b[33m\u001b[0m] from \u001b[34mpitsisEfficientConvolutionalNeural2019a\u001b[0m with board: \u001b[31mZynq US+ (ZU9EG) {Quad-FPGA}\u001b[0m (N/A):\n",
      "            Score: \u001b[32m\u001b[0m, Size: \u001b[32m11 MB\u001b[0m, Latency: \u001b[32m4334 FPS\u001b[0m, Throughput: \u001b[32m265 GOP/s\u001b[0m, Power: \u001b[32m\u001b[0m\n",
      "    \u001b[34mCustom (Sentinel-2)\u001b[0m:\n",
      "        - \u001b[31mCloudScout\u001b[0m (CNN) [\u001b[33m\u001b[0m] from \u001b[34mrapuanoFPGAbasedHardwareAccelerator2021a\u001b[0m with board: \u001b[31mZynq US+ (ZU7EV) {ZCU106}\u001b[0m (RTL design (VHDL)):\n",
      "            Score: \u001b[32m92.0% OA\u001b[0m, Size: \u001b[32m13.3 MB\u001b[0m, Latency: \u001b[32m141.7 ms\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m3.4 W\u001b[0m\n",
      "    Total: 19\n",
      "\n",
      "\u001b[34mObject detection\u001b[0m task (total: 18):\n",
      "    \u001b[34mDOTAv1.0\u001b[0m:\n",
      "        - \u001b[31mGhost-YOLOS\u001b[0m (YOLOv3) [\u001b[33mGhostNet\u001b[0m] from \u001b[34myangLightweightDetectionMethod2023\u001b[0m with board: \u001b[31mZynq 7000 (Z7020) {}\u001b[0m (RTL design (Verilog)):\n",
      "            Score: \u001b[32m62.58% mAP\u001b[0m, Size: \u001b[32m12.6 MB\u001b[0m, Latency: \u001b[32m3 FPS\u001b[0m, Throughput: \u001b[32m29.53 GOP/s\u001b[0m, Power: \u001b[32m2.98 W\u001b[0m\n",
      "        - \u001b[31mYOLOv2\u001b[0m (YOLOv2) [\u001b[33mDarknet19\u001b[0m] from \u001b[34mniAlgorithmHardwareCoOptimization2023\u001b[0m with board: \u001b[31mVirtex-7 (VX690T) {VC709}\u001b[0m (RTL design (Verilog)):\n",
      "            Score: \u001b[32m67.30% mAP\u001b[0m, Size: \u001b[32m49.4 MB\u001b[0m, Latency: \u001b[32m981.4 ms\u001b[0m, Throughput: \u001b[32m387 GOP/s\u001b[0m, Power: \u001b[32m14.97 W\u001b[0m\n",
      "        - \u001b[31mImproved YOLOv2\u001b[0m (YOLOv2) [\u001b[33mDarknet19\u001b[0m] from \u001b[34myanAutomaticDeploymentConvolutional2022a\u001b[0m with board: \u001b[31mArtix-7 (XC7A200T) (AC701)\u001b[0m (RTL design (VHDL)):\n",
      "            Score: \u001b[32m67.30% mAP\u001b[0m, Size: \u001b[32m49.4 MB\u001b[0m, Latency: \u001b[32m17120 ms\u001b[0m, Throughput: \u001b[32m379.55 GOP/s\u001b[0m, Power: \u001b[32m3.41 W\u001b[0m\n",
      "        - \u001b[31mImproved YOLOv2\u001b[0m (YOLOv2) [\u001b[33mDarknet19\u001b[0m] from \u001b[34mzhangFPGAImplementationCNNbased2021a\u001b[0m with board: \u001b[31mZynq 7000 (Z7035) {}\u001b[0m (RTL design (VHDL)):\n",
      "            Score: \u001b[32m67.32% mAP\u001b[0m, Size: \u001b[32m\u001b[0m, Latency: \u001b[32m3.4s\u001b[0m, Throughput: \u001b[32m111.5 GOP/s\u001b[0m, Power: \u001b[32m5.96 W\u001b[0m\n",
      "    \u001b[34mSSDD\u001b[0m:\n",
      "        - \u001b[31mCNN1@1.6\u001b[0m (YOLOv2) [\u001b[33mMobileNetv1\u001b[0m] from \u001b[34myangAlgorithmHardwareCodesign2022\u001b[0m with board: \u001b[31mVirtex-7 (VX690T) {VC709}\u001b[0m (HLS (Vitis)):\n",
      "            Score: \u001b[32m94% AP\u001b[0m, Size: \u001b[32m0.51 MB\u001b[0m, Latency: \u001b[32m385 FPS\u001b[0m, Throughput: \u001b[32m221 GOP/s\u001b[0m, Power: \u001b[32m4.8 W\u001b[0m\n",
      "        - \u001b[31mCNN3@1.6\u001b[0m (YOLOv2) [\u001b[33mMobileNetv2\u001b[0m] from \u001b[34myangAlgorithmHardwareCodesign2022\u001b[0m with board: \u001b[31mVirtex-7 (VX690T) {VC709}\u001b[0m (HLS (Vitis)):\n",
      "            Score: \u001b[32m93.3% AP\u001b[0m, Size: \u001b[32m0.13 MB\u001b[0m, Latency: \u001b[32m380 FPS\u001b[0m, Throughput: \u001b[32m214 GOP/s\u001b[0m, Power: \u001b[32m4.5 W\u001b[0m\n",
      "        - \u001b[31mCNN6@1.6\u001b[0m (YOLOv2) [\u001b[33mSqueezeNet\u001b[0m] from \u001b[34myangAlgorithmHardwareCodesign2022\u001b[0m with board: \u001b[31mVirtex-7 (VX690T) {VC709}\u001b[0m (HLS (Vitis)):\n",
      "            Score: \u001b[32m92.8% AP\u001b[0m, Size: \u001b[32m0.27 MB\u001b[0m, Latency: \u001b[32m\u001b[0m, Throughput: \u001b[32m235 GOP/s\u001b[0m, Power: \u001b[32m5.1 W\u001b[0m\n",
      "    \u001b[34mMulti-drone (custom)\u001b[0m:\n",
      "        - \u001b[31mSSD 0.25x\u001b[0m (SSD300-HW) [\u001b[33mVGG16\u001b[0m] from \u001b[34msuhAlgorithmHardwareCoOptimizationEnergyEfficient2021\u001b[0m with board: \u001b[31mZynq US+ (ZU3EG) {OVC3}\u001b[0m (N/A):\n",
      "            Score: \u001b[32m76.2% mAP\u001b[0m, Size: \u001b[32m\u001b[0m, Latency: \u001b[32m34.18 FPS\u001b[0m, Throughput: \u001b[32m138 GOP/s\u001b[0m, Power: \u001b[32m2.4 W\u001b[0m\n",
      "        - \u001b[31mSSD 0.5x\u001b[0m (SSD300-HW) [\u001b[33mVGG16\u001b[0m] from \u001b[34msuhAlgorithmHardwareCoOptimizationEnergyEfficient2021\u001b[0m with board: \u001b[31mZynq US+ (ZU3EG) {OVC3}\u001b[0m (N/A):\n",
      "            Score: \u001b[32m83.9% mAP\u001b[0m, Size: \u001b[32m\u001b[0m, Latency: \u001b[32m9.6 FPS\u001b[0m, Throughput: \u001b[32m150 GOP/s\u001b[0m, Power: \u001b[32m2.6 W\u001b[0m\n",
      "        - \u001b[31mSSD 1.0x\u001b[0m (SSD300-HW) [\u001b[33mVGG16\u001b[0m] from \u001b[34msuhAlgorithmHardwareCoOptimizationEnergyEfficient2021\u001b[0m with board: \u001b[31mZynq US+ (ZU3EG) {OVC3}\u001b[0m (N/A):\n",
      "            Score: \u001b[32m88.4% mAP\u001b[0m, Size: \u001b[32m\u001b[0m, Latency: \u001b[32m2.56 FPS\u001b[0m, Throughput: \u001b[32m158 GOP/s\u001b[0m, Power: \u001b[32m2.0 W\u001b[0m\n",
      "    \u001b[34mDIOR\u001b[0m:\n",
      "        - \u001b[31mRFA-YOLO\u001b[0m (YOLOv4) [\u001b[33mMobileNeXt\u001b[0m] from \u001b[34mliEdgeRealtimeObject2023a\u001b[0m with board: \u001b[31mZynq US+ (ZU7EV) {ZCU104}\u001b[0m (Vitis AI (N/A)):\n",
      "            Score: \u001b[32m64.85% mAP\u001b[0m, Size: \u001b[32m24.75 MB\u001b[0m, Latency: \u001b[32m27.97 FPS\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m15.82 W\u001b[0m\n",
      "        - \u001b[31mYOLOv4-MobileNetv3\u001b[0m (YOLOv4) [\u001b[33mMobileNetv3\u001b[0m] from \u001b[34mzhaoHardwareAccelerationSatellite2023a\u001b[0m with board: \u001b[31mZynq US+ (ZU9EG) {Kria KV260}\u001b[0m (Vitis AI (2.5)):\n",
      "            Score: \u001b[32m82.61% mAP\u001b[0m, Size: \u001b[32m5.69 MB\u001b[0m, Latency: \u001b[32m48.14 FPS\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m7.2 W\u001b[0m\n",
      "    \u001b[34mCustom (UAV)\u001b[0m:\n",
      "        - \u001b[31mAP2D-Net\u001b[0m (CNN) [\u001b[33m\u001b[0m] from \u001b[34mliNovelCNNBasedAP2DNet2020\u001b[0m with board: \u001b[31mZynq US+ (ZU3EG) {Ultra96}\u001b[0m (RTL design (N/A)):\n",
      "            Score: \u001b[32m55.0% mIoU\u001b[0m, Size: \u001b[32m\u001b[0m, Latency: \u001b[32m30.53 FPS\u001b[0m, Throughput: \u001b[32m130.2 GOP/s\u001b[0m, Power: \u001b[32m5.59 W\u001b[0m\n",
      "        - \u001b[31mYOLOv4-tiny 3L\u001b[0m (YOLOv4-tiny) [\u001b[33mDarknet53-tiny\u001b[0m] from \u001b[34mnguyenFPGASoCImplementationYOLOv42024\u001b[0m with board: \u001b[31mZynq US+ (ZU7EV) {ZCU104}\u001b[0m (Vitis AI (N/A)):\n",
      "            Score: \u001b[32m72.24% mAP\u001b[0m, Size: \u001b[32m24.1 MB\u001b[0m, Latency: \u001b[32m125 FPS\u001b[0m, Throughput: \u001b[32m15.3 GOP/s\u001b[0m, Power: \u001b[32m26.4 W\u001b[0m\n",
      "    \u001b[34mSimulated (RGB)\u001b[0m:\n",
      "        - \u001b[31mImproved YOLOv3\u001b[0m (YOLOv3) [\u001b[33mDarkNet53\u001b[0m] from \u001b[34mwuDesignImplementationRemote2021\u001b[0m with board: \u001b[31mZynq US+ (ZU9EG) {}\u001b[0m (HLS (N/A)):\n",
      "            Score: \u001b[32m92% OA\u001b[0m, Size: \u001b[32m8.5 MB\u001b[0m, Latency: \u001b[32m7 ms\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m\u001b[0m\n",
      "    \u001b[34mNWPU VHR-10\u001b[0m:\n",
      "        - \u001b[31mCBFF-SSD\u001b[0m (SSD) [\u001b[33mMobileNetv1\u001b[0m] from \u001b[34mliEfficientObjectDetection2019a\u001b[0m with board: \u001b[31mZynq 7000 (Z7100) {}\u001b[0m (RTL design (Verilog)):\n",
      "            Score: \u001b[32m91.42 mAP\u001b[0m, Size: \u001b[32m\u001b[0m, Latency: \u001b[32m42.59 ms\u001b[0m, Throughput: \u001b[32m452.8 GOP/s\u001b[0m, Power: \u001b[32m19.52 W\u001b[0m\n",
      "    \u001b[34mDAC 2018\u001b[0m:\n",
      "        - \u001b[31mCNN\u001b[0m (CNN) [\u001b[33m\u001b[0m] from \u001b[34mwangAccelerationImplementationConvolutional2019\u001b[0m with board: \u001b[31mZynq 7000 (Z7020) {PYNQ-Z1}\u001b[0m (HLS (Vivado)):\n",
      "            Score: \u001b[32m21% mIoU\u001b[0m, Size: \u001b[32m\u001b[0m, Latency: \u001b[32m7 FPS\u001b[0m, Throughput: \u001b[32m69.8 GOP/s\u001b[0m, Power: \u001b[32m2.38 W\u001b[0m\n",
      "    \u001b[34mFastenerDataset\u001b[0m:\n",
      "        - \u001b[31mImproved YOLOv4-tiny\u001b[0m (YOLOv4-tiny) [\u001b[33mCSPDarknet53\u001b[0m] from \u001b[34myuImprovedLightweightDeep2024\u001b[0m with board: \u001b[31mZynq US+ (ZU7EV) {ZCU104}\u001b[0m (Vitis AI (1.4)):\n",
      "            Score: \u001b[32m95.1% mAP\u001b[0m, Size: \u001b[32m\u001b[0m, Latency: \u001b[32m555 FPS\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m20 W\u001b[0m\n",
      "    Total: 18\n",
      "\n",
      "\u001b[34mPixel classification\u001b[0m task (total: 12):\n",
      "    \u001b[34mUniversity of Pavia\u001b[0m:\n",
      "        - \u001b[31mSAM-GNN\u001b[0m (GNN) [\u001b[33m\u001b[0m] from \u001b[34mchellaswamyFPGAbasedRemoteTarget2024\u001b[0m with board: \u001b[31mVirtex-7 (VX690T) {}\u001b[0m (RTL design (VHDL)):\n",
      "            Score: \u001b[32m95.05% OA\u001b[0m, Size: \u001b[32m\u001b[0m, Latency: \u001b[32m\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m\u001b[0m\n",
      "        - \u001b[31m2D CNN\u001b[0m (CNN) [\u001b[33m\u001b[0m] from \u001b[34mheConfigurable2D3D2023a\u001b[0m with board: \u001b[31mZynq US+ (ZU15EG) {Alinx AXU15EG}\u001b[0m (RTL design (N/A)):\n",
      "            Score: \u001b[32m98.24% OA\u001b[0m, Size: \u001b[32m1.2 MB\u001b[0m, Latency: \u001b[32m0.097 ms\u001b[0m, Throughput: \u001b[32m7.07 GOP/s\u001b[0m, Power: \u001b[32m8.4 W\u001b[0m\n",
      "        - \u001b[31m3D CNN\u001b[0m (CNN) [\u001b[33m\u001b[0m] from \u001b[34mheConfigurable2D3D2023a\u001b[0m with board: \u001b[31mZynq US+ (ZU15EG) {Alinx AXU15EG}\u001b[0m (RTL design (N/A)):\n",
      "            Score: \u001b[32m94.09% OA\u001b[0m, Size: \u001b[32m0.12 MB\u001b[0m, Latency: \u001b[32m1.11 ms\u001b[0m, Throughput: \u001b[32m3.808 GOP/s\u001b[0m, Power: \u001b[32m8.4 W\u001b[0m\n",
      "        - \u001b[31mHybridSN\u001b[0m (CNN) [\u001b[33m\u001b[0m] from \u001b[34mheConfigurable2D3D2023a\u001b[0m with board: \u001b[31mZynq US+ (ZU15EG) {Alinx AXU15EG}\u001b[0m (RTL design (N/A)):\n",
      "            Score: \u001b[32m100% OA\u001b[0m, Size: \u001b[32m20.5 MB\u001b[0m, Latency: \u001b[32m7.71 ms\u001b[0m, Throughput: \u001b[32m13.18 GOP/s\u001b[0m, Power: \u001b[32m8.4 W\u001b[0m\n",
      "        - \u001b[31mLPDBL\u001b[0m (Diverse) [\u001b[33m\u001b[0m] from \u001b[34mshibiOnboardTargetDetection2021a\u001b[0m with board: \u001b[31mVirtex-7 (VX690T) {}\u001b[0m (RTL design (VHDL)):\n",
      "            Score: \u001b[32m\u001b[0m, Size: \u001b[32m\u001b[0m, Latency: \u001b[32m\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m\u001b[0m\n",
      "        - \u001b[31mSVM\u001b[0m (SVM) [\u001b[33m\u001b[0m] from \u001b[34mmartinsRealtimeSVMbasedHardware2024\u001b[0m with board: \u001b[31mZynq 7000 (Z7020) {}\u001b[0m (RTL design (VHDL)):\n",
      "            Score: \u001b[32m82.48% AA\u001b[0m, Size: \u001b[32m\u001b[0m, Latency: \u001b[32m\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m\u001b[0m\n",
      "    \u001b[34mCustom (UAV)\u001b[0m:\n",
      "        - \u001b[31mWeightless Neural Systems\u001b[0m (Diverse) [\u001b[33m\u001b[0m] from \u001b[34mtorresCombinedWeightlessNeural2020\u001b[0m with board: \u001b[31mZynq 7000 (Z7020) {}\u001b[0m (N/A):\n",
      "            Score: \u001b[32m90.0% OA\u001b[0m, Size: \u001b[32m\u001b[0m, Latency: \u001b[32m\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m\u001b[0m\n",
      "        - \u001b[31mDecision Tree\u001b[0m (Diverse) [\u001b[33m\u001b[0m] from \u001b[34mfraczekEmbeddedVisionSystem2018\u001b[0m with board: \u001b[31mZynq 7000 (Z7020) {Arty Z7}\u001b[0m (RTL design (Verilog)):\n",
      "            Score: \u001b[32m92.1% OA\u001b[0m, Size: \u001b[32m\u001b[0m, Latency: \u001b[32m300 ms\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m3.5 W\u001b[0m\n",
      "    \u001b[34mAVIRIS-NG\u001b[0m:\n",
      "        - \u001b[31mCAL-SC2S\u001b[0m (Diverse) [\u001b[33m\u001b[0m] from \u001b[34mgyaneshwarRealtimeSCSUP2022\u001b[0m with board: \u001b[31mArtix-7 (XC7A35T) {Arty-35T}\u001b[0m (RTL design (XSG)):\n",
      "            Score: \u001b[32m29.69% OA\u001b[0m, Size: \u001b[32m\u001b[0m, Latency: \u001b[32m2410 ms\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m0.358 W\u001b[0m\n",
      "        - \u001b[31mSVM\u001b[0m (SVM) [\u001b[33m\u001b[0m] from \u001b[34mgyaneshwarRealtimeSCSUP2022\u001b[0m with board: \u001b[31mArtix-7 (XC7A35T) {Arty-35T}\u001b[0m (RTL design (XSG)):\n",
      "            Score: \u001b[32m20.71% OA\u001b[0m, Size: \u001b[32m\u001b[0m, Latency: \u001b[32m2160 ms\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m0.224 W\u001b[0m\n",
      "    \u001b[34mCustom (ALSAT-2A)\u001b[0m:\n",
      "        - \u001b[31mFuzzy ARTMAP\u001b[0m (Diverse) [\u001b[33m\u001b[0m] from \u001b[34myahiaouiParallelizationFuzzyARTMAP2017a\u001b[0m with board: \u001b[31mVirtex-6 (VLX240T) {}\u001b[0m (RTL design (VHDL)):\n",
      "            Score: \u001b[32m94.8% OA\u001b[0m, Size: \u001b[32m\u001b[0m, Latency: \u001b[32m96 FPS\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m0.15 W\u001b[0m\n",
      "    \u001b[34mAirport-Beach-Urban\u001b[0m:\n",
      "        - \u001b[31mDeep Belief Network\u001b[0m (Diverse) [\u001b[33m\u001b[0m] from \u001b[34mboyleHighlevelFPGADesign2023a\u001b[0m with board: \u001b[31mZynq US+ (ZU7EV) {ZCU104}\u001b[0m (HLS (Vitis)):\n",
      "            Score: \u001b[32m\u001b[0m, Size: \u001b[32m\u001b[0m, Latency: \u001b[32m5.4 ms\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m\u001b[0m\n",
      "    Total: 12\n",
      "\n",
      "\u001b[34mSegmentation\u001b[0m task (total: 6):\n",
      "    \u001b[34mPotsdam\u001b[0m:\n",
      "        - \u001b[31mENet\u001b[0m (Diverse) [\u001b[33m\u001b[0m] from \u001b[34msabogalMethodologyEvaluatingAnalyzing2021a\u001b[0m with board: \u001b[31mZynq US+ (ZU3EG) {UltraZed-EG}\u001b[0m (Vitis AI (DNNDK v3.1)):\n",
      "            Score: \u001b[32m63.3% mIoU\u001b[0m, Size: \u001b[32m0.36 MB\u001b[0m, Latency: \u001b[32m25.2 FPS\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m3.36 W\u001b[0m\n",
      "        - \u001b[31mESPNet\u001b[0m (Diverse) [\u001b[33m\u001b[0m] from \u001b[34msabogalMethodologyEvaluatingAnalyzing2021a\u001b[0m with board: \u001b[31mZynq US+ (ZU3EG) {UltraZed-EG}\u001b[0m (Vitis AI (DNNDK v3.1)):\n",
      "            Score: \u001b[32m55.5% mIoU\u001b[0m, Size: \u001b[32m0.33 MB\u001b[0m, Latency: \u001b[32m11.7 FPS\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m3.08 W\u001b[0m\n",
      "        - \u001b[31mFPN\u001b[0m (Diverse) [\u001b[33m\u001b[0m] from \u001b[34msabogalMethodologyEvaluatingAnalyzing2021a\u001b[0m with board: \u001b[31mZynq US+ (ZU3EG) {UltraZed-EG}\u001b[0m (Vitis AI (DNNDK v3.1)):\n",
      "            Score: \u001b[32m65.3% mIoU\u001b[0m, Size: \u001b[32m5.84 MB\u001b[0m, Latency: \u001b[32m14.1 FPS\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m4.03 W\u001b[0m\n",
      "        - \u001b[31mU-Net\u001b[0m (U-Net) [\u001b[33m\u001b[0m] from \u001b[34msabogalMethodologyEvaluatingAnalyzing2021a\u001b[0m with board: \u001b[31mZynq US+ (ZU3EG) {UltraZed-EG}\u001b[0m (Vitis AI (DNNDK v3.1)):\n",
      "            Score: \u001b[32m61.4% mIoU\u001b[0m, Size: \u001b[32m7.40 MB\u001b[0m, Latency: \u001b[32m2.7 FPS\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m3.38 W\u001b[0m\n",
      "    \u001b[34m38-Cloud\u001b[0m:\n",
      "        - \u001b[31mC-FCN++\u001b[0m (CNN) [\u001b[33m\u001b[0m] from \u001b[34mbahlLowpowerNeuralNetworks2019a\u001b[0m with board: \u001b[31mCyclone V (5CSXC6) {}\u001b[0m (HLS (VGT)):\n",
      "            Score: \u001b[32m79.30% mIoU\u001b[0m, Size: \u001b[32m0.047 MB\u001b[0m, Latency: \u001b[32m150 ms\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m\u001b[0m\n",
      "    \u001b[34mCustom (Landsat-8-OLI)\u001b[0m:\n",
      "        - \u001b[31mRoller Dung Bettle Clustering\u001b[0m (Diverse) [\u001b[33m\u001b[0m] from \u001b[34mratnakumarHighSpeedRoller2021\u001b[0m with board: \u001b[31mVirtex-6 (VLX240T) {}\u001b[0m (RTL design (Verilog)):\n",
      "            Score: \u001b[32m37.45% SSIM\u001b[0m, Size: \u001b[32m\u001b[0m, Latency: \u001b[32m109670 ms\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m0.1155 W\u001b[0m\n",
      "    Total: 6\n",
      "\n",
      "\u001b[34mRegression\u001b[0m task (total: 1):\n",
      "    \u001b[34mSimulated (SAR)\u001b[0m:\n",
      "        - \u001b[31mMLP\u001b[0m (MLP) [\u001b[33m\u001b[0m] from \u001b[34mhammoudArtificialNeuralNetworksBased2022a\u001b[0m with board: \u001b[31mZynq 7000 (Z7020) {PYNQ-Z1}\u001b[0m (N/A):\n",
      "            Score: \u001b[32m\u001b[0m, Size: \u001b[32m\u001b[0m, Latency: \u001b[32m\u001b[0m, Throughput: \u001b[32m\u001b[0m, Power: \u001b[32m0.084 W\u001b[0m\n",
      "    Total: 1\n"
     ]
    }
   ],
   "source": [
    "# Print the number of models for each task\n",
    "task_counts = datapoints_df[\"Task\"].value_counts()\n",
    "print(task_counts)\n",
    "# # Print the number of models for each backbone\n",
    "# backbone_counts = datapoints_df[\"Backbone\"].value_counts()\n",
    "# print(f\"\\n{backbone_counts}\")\n",
    "\n",
    "\n",
    "# For each Task, group by dataset and print each model name and backbones\n",
    "for task, value in task_counts.items():\n",
    "    print(f\"\\n{b}{task}{e} task (total: {value}):\")\n",
    "    nb_item = 0\n",
    "    for dataset in dataset_counts.index:\n",
    "        if dataset.split(\"{\")[1][:-1].strip().upper() == task.upper():\n",
    "            print(f\"    {b}{dataset.split('{')[0].strip()}{e}:\")\n",
    "            for index, row in datapoints_df.iterrows():\n",
    "                if row[\"Task\"] == task and row[\"Dataset\"] == dataset:\n",
    "                    print(\n",
    "                        f\"        - {r}{row['Model']}{e} ({row['Equivalent model']}) [{y}{row['Backbone']}{e}] from {b}{row['BBT Citation Key']}{e} with board: {r}{row['Board']}{e} ({row['Implementation']}):\"\n",
    "                    )\n",
    "                    print(\n",
    "                        f\"            Score: {g}{row['Model performance']}{e}, Size: {g}{row['Model size']}{e}, Latency: {g}{row['Model latency']}{e}, Throughput: {g}{row['Model throughput']}{e}, Power: {g}{row['Power consumption']}{e}\"\n",
    "                    )\n",
    "                    nb_item += 1\n",
    "\n",
    "    print(f\"    Total: {nb_item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per task category anaylysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | BBT Citation Key                                    |   Missing metrics | Model            | Equivalent model   | Backbone   | Dataset                                 | Application                      | Model latency   | Model performance   | Model size   | Model throughput   | Power consumption   |\n",
      "|---:|:----------------------------------------------------|------------------:|:-----------------|:-------------------|:-----------|:----------------------------------------|:---------------------------------|:----------------|:--------------------|:-------------|:-------------------|:--------------------|\n",
      "| 31 | hashimotoShipClassificationSAR2019a                 |                 3 | CNN              | CNN                |            | Custom (ALOS-2) {Classification}        | Binary ship classification       | 330 ms          | 100% OA             |              |                    |                     |\n",
      "| 25 | rapuanoFPGAbasedHardwareAccelerator2021a            |                 1 | CloudScout       | CNN                |            | Custom (Sentinel-2) {Classification}    | Binary cloud coverage            | 141.7 ms        | 92.0% OA            | 13.3 MB      |                    | 3.4 W               |\n",
      "| 12 | ieracitanoExplainableEmbeddedNeural2024             |                 2 | CNN              | CNN                |            | Kaggle SSI {Classification}             | Binary ship classification       | 1.01 ms         | 93.44% OA           |              |                    | 1.9 W               |\n",
      "| 17 | pitonakCloudSatNet1FPGABasedHardwareAccelerated2022 |                 1 | CloudSatNet-1 Q2 | CNN                |            | L8 Biome {Classification}               | Binary cloud coverage            | 15.46 FPS       | 83.41% OA           | 1.43 MB      |                    | 2.55 W              |\n",
      "| 18 | pitonakCloudSatNet1FPGABasedHardwareAccelerated2022 |                 1 | CloudSatNet-1 Q4 | CNN                |            | L8 Biome {Classification}               | Binary cloud coverage            | 15.47 FPS       | 87.42% OA           | 3.06 MB      |                    | 2.55 W              |\n",
      "|  9 | zhangAccurateLowlatencyEfficient2022a               |                 1 | GNN              | GNN                |            | MSTAR {Classification}                  | Military targets                 | 0.105 ms        | 99.09% OA           | 0.96 MB      |                    | 6.3 W               |\n",
      "| 28 | weiFPGABasedHybridTypeImplementation2019            |                 2 | Modified LeNet-5 | LeNet-5            | LeNet-5    | MSTAR {Classification}                  | Military targets                 | 2.29 ms         | 97.77% OA           | 1.66 MB      |                    |                     |\n",
      "| 53 | chenHardwareImplementationConvolutional2020         |                 3 | LeNet-5          | LeNet-5            | LeNet-5    | MSTAR {Classification}                  | Military targets                 | 2.29 ms         | 98.18% OA           |              |                    |                     |\n",
      "| 54 | zhangAcceleratingGNNbasedSAR2023                    |                 2 | GNN              | GNN                |            | MSTAR {Classification}                  | Military targets                 | 759 FPS         |                     |              | 400 GOP/s          | 38 W                |\n",
      "| 37 | niAlgorithmHardwareCoOptimization2023               |                 0 | ResNet-34        | ResNet-34          | ResNet-34  | NWPU-RESISC45 {Classification}          | Terrain type                     | 40.2 ms         | 92.81% OA           | 21.29 MB     | 182 GOP/s          | 14.97 W             |\n",
      "| 38 | niAlgorithmHardwareCoOptimization2023               |                 0 | VGG16            | VGG16              | VGG16      | NWPU-RESISC45 {Classification}          | Terrain type                     | 89.1 ms         | 91.90% OA           | 14.7 MB      | 344 GOP/s          | 14.97 W             |\n",
      "| 50 | yanAutomaticDeploymentConvolutional2022a            |                 0 | Improved VGG16   | VGG16              | VGG16      | NWPU-RESISC45 {Classification}          | Terrain type                     | 1780 ms         | 88.08% OA           | 14.8 MB      | 40.96 GOP/s        | 3.41 W              |\n",
      "| 55 | zhangEfficientFPGABasedImplementation2020           |                 0 | Q-IORN           | IORN4              | VGG16      | NWPU-RESISC45 {Classification}          | Terrain type                     | 6.77 FPS        | 88.31% OA           | 121.51 MB    | 209.6 GOP/s        | 6.32 W              |\n",
      "|  4 | pitsisEfficientConvolutionalNeural2019a             |                 2 | CNN              | CNN                |            | Simulated (1-D Signal) {Classification} | Redshift estimation [regression] | 4334 FPS        |                     | 11 MB        | 265 GOP/s          |                     |\n",
      "| 13 | zhangExtremelyPipelinedFPGAbased2023a               |                 1 | A2NN             | VGG11              | VGG11      | UC-Merced Land Use {Classification}     | Terrain type                     | 203 FPS         | 94.76% Prec         |              | 3047 GOP/s         | 8.27 W              |\n"
     ]
    }
   ],
   "source": [
    "# --- Print the dataframe with only model trained for classification, sorted by dataset ---\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "# Filter the dataframe to keep only the models trained for classification, having less than 4 missing metrics\n",
    "\n",
    "classification_df: DataFrame = datapoints_df[datapoints_df[\"Task\"] == \"Classification\"]\n",
    "\n",
    "classification_df = classification_df[classification_df[\"Missing metrics\"] < 4]\n",
    "\n",
    "# Sort the dataframe by dataset\n",
    "\n",
    "classification_df = classification_df.sort_values(by=\"Dataset\")\n",
    "\n",
    "\n",
    "# Print the dataframe with tabulate\n",
    "\n",
    "print(\n",
    "\n",
    "    tabulate(\n",
    "        classification_df[\n",
    "            [\n",
    "\n",
    "                \"BBT Citation Key\",\n",
    "                \"Missing metrics\",\n",
    "                \"Model\",\n",
    "\n",
    "                \"Equivalent model\",\n",
    "                \"Backbone\",\n",
    "                \"Dataset\",\n",
    "                \"Application\",\n",
    "                # \"Board\",\n",
    "                # \"Implementation\",\n",
    "                \"Model latency\",\n",
    "                \"Model performance\",\n",
    "                \"Model size\",\n",
    "\n",
    "                \"Model throughput\",\n",
    "                \"Power consumption\",\n",
    "            ]\n",
    "        ],\n",
    "        headers=\"keys\",\n",
    "        tablefmt=\"pipe\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old code from previous data format\n",
    "\n",
    "Should not run anymore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the Hardware\n",
    "\n",
    "Which FPGA family, specific model and evaluation boards are used?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m33\u001b[0m different device tags, in total \u001b[32m60\u001b[0m tags:\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Virtex-6\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Kintex US rad-hard (XQRKU060)\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Zynq US+ (ZU7EV) {ZCU106}\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Zynq 7000 (Z7020) {PYNQ-Z2}\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Zynq US+ (ZU3EG) {UltraZed-EG}\"\u001b[0m\n",
      " - \u001b[31m  3\u001b[0m items for \u001b[34m\"Virtex-7 (VX690T)\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Zynq US+ (ZU3EG) {OVC3}\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Zynq US+ (ZU9EG)\"\u001b[0m\n",
      " - \u001b[31m  3\u001b[0m items for \u001b[34m\"Zynq 7000 (Z7020)\"\u001b[0m\n",
      " - \u001b[31m  3\u001b[0m items for \u001b[34m\"Virtex-7 (VX690T) {VC709}\"\u001b[0m\n",
      " - \u001b[31m  2\u001b[0m items for \u001b[34m\"Zynq 7000 (Z7020) {Zedboard}\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Artix-7 (XC7A35T) {Arty-35T}\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Zynq 7000 (Z7035)\"\u001b[0m\n",
      " - \u001b[31m  3\u001b[0m items for \u001b[34m\"Zynq 7000 (Z7020) {PYNQ-Z1}\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Kintex US (XCKU040) {KCU105}\"\u001b[0m\n",
      " - \u001b[31m  5\u001b[0m items for \u001b[34m\"Zynq US+ (ZU7EV) {ZCU104}\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Zynq 7000 (Z7020) {Z-turn}\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Zynq US+ (ZU15EG) {Alinx AXU15EG}\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Alveo U280\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Zynq US+ (ZU9EG) (Kria KV260)\"\u001b[0m\n",
      " - \u001b[31m  2\u001b[0m items for \u001b[34m\"Cyclone V (5CSXC6)\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Virtex-6 (XC6VLX240T)\"\u001b[0m\n",
      " - \u001b[31m 13\u001b[0m items for \u001b[34m\"???\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Zynq US+ (ZU9EG) {Quad-FPGA}\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"ASIC\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Virtex US (VU440) {ProFPGA}\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Zynq 7000 (Z7100)\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Artix-7\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Zynq 7000 (Z7020) {Arty Z7}\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Spartan-3A (XC3SD1800A)\"\u001b[0m\n",
      " - \u001b[31m  2\u001b[0m items for \u001b[34m\"Kintex-7 (XC7K325T)\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Zynq 7000 (Z7045) {ZC706}\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Zynq US+ (ZU3EG) {Ultra96}\"\u001b[0m\n",
      "\u001b[31m14\u001b[0m different families, in total \u001b[32m60\u001b[0m:\n",
      " - \u001b[31m  2\u001b[0m items for \u001b[34m\"Virtex-6\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Kintex US rad-hard\"\u001b[0m\n",
      " - \u001b[31m 13\u001b[0m items for \u001b[34m\"Zynq US+\"\u001b[0m\n",
      " - \u001b[31m 14\u001b[0m items for \u001b[34m\"Zynq 7000\"\u001b[0m\n",
      " - \u001b[31m  6\u001b[0m items for \u001b[34m\"Virtex-7\"\u001b[0m\n",
      " - \u001b[31m  2\u001b[0m items for \u001b[34m\"Artix-7\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Kintex US\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Alveo U280\"\u001b[0m\n",
      " - \u001b[31m  2\u001b[0m items for \u001b[34m\"Cyclone V\"\u001b[0m\n",
      " - \u001b[31m 13\u001b[0m items for \u001b[34m\"???\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"ASIC\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Virtex US\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Spartan-3A\"\u001b[0m\n",
      " - \u001b[31m  2\u001b[0m items for \u001b[34m\"Kintex-7\"\u001b[0m\n",
      "\u001b[31m18\u001b[0m different models, in total \u001b[32m60\u001b[0m:\n",
      " - \u001b[31m 17\u001b[0m items for \u001b[34m\"None\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"XQRKU060\"\u001b[0m\n",
      " - \u001b[31m  6\u001b[0m items for \u001b[34m\"ZU7EV\"\u001b[0m\n",
      " - \u001b[31m 11\u001b[0m items for \u001b[34m\"Z7020\"\u001b[0m\n",
      " - \u001b[31m  3\u001b[0m items for \u001b[34m\"ZU3EG\"\u001b[0m\n",
      " - \u001b[31m  6\u001b[0m items for \u001b[34m\"VX690T\"\u001b[0m\n",
      " - \u001b[31m  3\u001b[0m items for \u001b[34m\"ZU9EG\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"XC7A35T\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Z7035\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"XCKU040\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"ZU15EG\"\u001b[0m\n",
      " - \u001b[31m  2\u001b[0m items for \u001b[34m\"5CSXC6\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"XC6VLX240T\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"VU440\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Z7100\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"XC3SD1800A\"\u001b[0m\n",
      " - \u001b[31m  2\u001b[0m items for \u001b[34m\"XC7K325T\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Z7045\"\u001b[0m\n",
      "\u001b[31m18\u001b[0m different boards/evaluation kits, in total \u001b[32m60\u001b[0m:\n",
      " - \u001b[31m 34\u001b[0m items for \u001b[34m\"None\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"ZCU106\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"PYNQ-Z2\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"UltraZed-EG\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"OVC3\"\u001b[0m\n",
      " - \u001b[31m  3\u001b[0m items for \u001b[34m\"VC709\"\u001b[0m\n",
      " - \u001b[31m  2\u001b[0m items for \u001b[34m\"Zedboard\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Arty-35T\"\u001b[0m\n",
      " - \u001b[31m  3\u001b[0m items for \u001b[34m\"PYNQ-Z1\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"KCU105\"\u001b[0m\n",
      " - \u001b[31m  5\u001b[0m items for \u001b[34m\"ZCU104\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Z-turn\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Alinx AXU15EG\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Quad-FPGA\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"ProFPGA\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Arty Z7\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"ZC706\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Ultra96\"\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[31m18\u001b[0m different implementations, in total \u001b[32m57\u001b[0m:\n",
      " - \u001b[31m  3\u001b[0m items for \u001b[34m\"RTL design (Verilog)\"\u001b[0m\n",
      " - \u001b[31m  7\u001b[0m items for \u001b[34m\"RTL design (VHDL)\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Vitis AI (DNNDK v3.1)\"\u001b[0m\n",
      " - \u001b[31m  4\u001b[0m items for \u001b[34m\"N/A\"\u001b[0m\n",
      " - \u001b[31m  3\u001b[0m items for \u001b[34m\"HLS (N/A)\"\u001b[0m\n",
      " - \u001b[31m  3\u001b[0m items for \u001b[34m\"HLS (Vivado)\"\u001b[0m\n",
      " - \u001b[31m  3\u001b[0m items for \u001b[34m\"HLS (Vitis)\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"XSG (RTL design)\"\u001b[0m\n",
      " - \u001b[31m  2\u001b[0m items for \u001b[34m\"FINN\"\u001b[0m\n",
      " - \u001b[31m  3\u001b[0m items for \u001b[34m\"Vitis AI (N/A)\"\u001b[0m\n",
      " - \u001b[31m  2\u001b[0m items for \u001b[34m\"RTL design (N/A)\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Vitis AI (2.5)\"\u001b[0m\n",
      " - \u001b[31m 13\u001b[0m items for \u001b[34m\"???\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"VGT (HLS)\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"PYNQ (HLS)\"\u001b[0m\n",
      " - \u001b[31m  6\u001b[0m items for \u001b[34m\"RTL design\"\u001b[0m\n",
      " - \u001b[31m  2\u001b[0m items for \u001b[34m\"Vitis/Vivado HLS\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Vitis AI (1.4)\"\u001b[0m\n",
      "\u001b[31m24\u001b[0m different tasks, in total \u001b[32m58\u001b[0m:\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Semantic segmentation (clustering)\"\u001b[0m\n",
      " - \u001b[31m  2\u001b[0m items for \u001b[34m\"Classification (Binary cloud coverage)\"\u001b[0m\n",
      " - \u001b[31m  3\u001b[0m items for \u001b[34m\"Semantic segmentation\"\u001b[0m\n",
      " - \u001b[31m  6\u001b[0m items for \u001b[34m\"Pixel classification (Terrain classification)\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Object detection (Drone/UAV)\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Object detection (Aircraft)\"\u001b[0m\n",
      " - \u001b[31m  5\u001b[0m items for \u001b[34m\"Object detection (diverse)\"\u001b[0m\n",
      " - \u001b[31m  2\u001b[0m items for \u001b[34m\"Scene classification\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Object detection (Ship detection)\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Scene feature extraction (oil spills)\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Classification (target detection)\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Anomaly detection (Pixel-by-Pixel)\"\u001b[0m\n",
      " - \u001b[31m  2\u001b[0m items for \u001b[34m\"Object classification (military targets)\"\u001b[0m\n",
      " - \u001b[31m  4\u001b[0m items for \u001b[34m\"Object detection\"\u001b[0m\n",
      " - \u001b[31m  4\u001b[0m items for \u001b[34m\"Classification\"\u001b[0m\n",
      " - \u001b[31m 14\u001b[0m items for \u001b[34m\"???\"\u001b[0m\n",
      " - \u001b[31m  2\u001b[0m items for \u001b[34m\"Ship classification\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Object tracking\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Landing site detection\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Pixel classification\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Pixel classification (UAV terrain classification)\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Object classification\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Object detection (Flying-object detection)\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Object detection (Railway track fastener defect detection)\"\u001b[0m\n",
      "\u001b[31m50\u001b[0m different models, in total \u001b[32m72\u001b[0m:\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Diverse (Roller Dung Bettle Clustering)\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"CloudScout\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"ENet\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"ESPNet\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"FPN\"\u001b[0m\n",
      " - \u001b[31m  2\u001b[0m items for \u001b[34m\"U-Net\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Diverse (LPDBL)\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"SSD 0.25x (SSD300-HW) {VGG16}\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"SSD 0.5x (SSD300-HW) {VGG16}\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"SSD 1.0x (SSD300-HW) {VGG16}\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"YOLO (YOLOv3)\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"GNN (SAM-GNN)\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"YOLOvs (Ghost-YOLOS) {GhostNet}\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"ResNet-34\"\u001b[0m\n",
      " - \u001b[31m  3\u001b[0m items for \u001b[34m\"VGG16\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"YOLOv2\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"YOLOv2 {MobileNetv1}\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"YOLOv2 {MobileNetv2}\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"YOLOv2 {SqueezeNet}\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Diverse (CAL-SC2S)\"\u001b[0m\n",
      " - \u001b[31m  3\u001b[0m items for \u001b[34m\"SVM\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"YOLOv2 (improved YOLOv2)\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"shallow NN\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"AlexNet (AlexNetLite)\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"MobileNetv1 (MobileNetv1Lite)\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Diverse (Deep Belief Network)\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"CNN (CloudSatNet-1 Q2)\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"CNN (CloudSatNet-1 Q4)\"\u001b[0m\n",
      " - \u001b[31m  2\u001b[0m items for \u001b[34m\"GNN\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"2D CNN\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"3D CNN\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"HybridSN\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"YOLOv4 (RFA-YOLO) {MobileNeXt}\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"VGG11 (A2NN)\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"YOLOv4 (YOLOv4-MobileNetv3) {MobileNetv3}\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Diverse (Fuzzy ARTMAP)\"\u001b[0m\n",
      " - \u001b[31m 14\u001b[0m items for \u001b[34m\"???\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Fully Convolutional Network (FCN)\"\u001b[0m\n",
      " - \u001b[31m  3\u001b[0m items for \u001b[34m\"CNN\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"MobileNetv1\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"YOLO (YOLOv2)\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Decision Trees (DT)\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Fully Connected NN (FCNN)\"\u001b[0m\n",
      " - \u001b[31m  2\u001b[0m items for \u001b[34m\"LeNet-5\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"BNN\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Diverse (Weightless Neural Systems)\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Diverse (AP2D-Net)\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Diverse (Improved Oriented Response Network)\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"YOLOv4 (YOLOv4-tiny 3L)\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"YOLOv4 (YOLOv4-tiny)\"\u001b[0m\n",
      "\u001b[31m8\u001b[0m different modalities tags, in total \u001b[32m53\u001b[0m:\n",
      " - \u001b[31m 21\u001b[0m items for \u001b[34m\"Modality: RGB\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Modality: RGB (3 bands from MSI)\"\u001b[0m\n",
      " - \u001b[31m  7\u001b[0m items for \u001b[34m\"Modality: HSI\"\u001b[0m\n",
      " - \u001b[31m  7\u001b[0m items for \u001b[34m\"Modality: SAR\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Modality: MSI (RGB + infrared)\"\u001b[0m\n",
      " - \u001b[31m 14\u001b[0m items for \u001b[34m\"Modality: ???\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Modality: 1-D Signal\"\u001b[0m\n",
      " - \u001b[31m  1\u001b[0m items for \u001b[34m\"Modality: RGB (UAV)\"\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Print all tags\n",
    "print(\n",
    "    f\"{r}{len(devices_tags)}{e} different device tags, in total {g}{get_total_in_dict_of_lists(devices_tags)}{e} tags:\"\n",
    ")\n",
    "for tag, keys in devices_tags.items():\n",
    "    print(f' - {r}{len(keys):>3}{e} items for {b}\"{tag[7:]}\"{e}')\n",
    "\n",
    "# Leave out articles that have \"Board: ???\" or \"Board: N/A\"\n",
    "# @TODO: Create a new dataframe per \"datapoint\", i.e., per experiment, so papers with several models or board will get as many datapoints\n",
    "\n",
    "print(\n",
    "    f\"{r}{len(devices_families)}{e} different families, in total {g}{get_total_in_dict(devices_families)}{e}:\"\n",
    ")\n",
    "for tag, keys in devices_families.items():\n",
    "    print(f' - {r}{keys:>3}{e} items for {b}\"{tag}\"{e}')\n",
    "\n",
    "print(\n",
    "    f\"{r}{len(devices_models)}{e} different models, in total {g}{get_total_in_dict(devices_models)}{e}:\"\n",
    ")\n",
    "for tag, keys in devices_models.items():\n",
    "    print(f' - {r}{keys:>3}{e} items for {b}\"{tag}\"{e}')\n",
    "\n",
    "print(\n",
    "    f\"{r}{len(devices_boards)}{e} different boards/evaluation kits, in total {g}{get_total_in_dict(devices_boards)}{e}:\"\n",
    ")\n",
    "for tag, keys in devices_boards.items():\n",
    "    print(f' - {r}{keys:>3}{e} items for {b}\"{tag}\"{e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles with the corresponding tags:\n",
      "\u001b[31m60\u001b[0m boards, \u001b[31m58\u001b[0m tasks, \u001b[31m72\u001b[0m models, \u001b[31m57\u001b[0m implementations and \u001b[31m53\u001b[0m modalities\n"
     ]
    }
   ],
   "source": [
    "# For all included articles, track tags starting by \"Board: \", \"Task: \", Model: \" and \"Implementation: \"\n",
    "# Some items may have multiple tags, so we need to track the number of items for each tag\n",
    "devices_tags = {}\n",
    "tasks_tags = {}\n",
    "models_tags = {}\n",
    "implementations_tags = {}\n",
    "modalities_tags = {}\n",
    "miscellaneoustags = {}\n",
    "\n",
    "# --- Split tags into categories ---\n",
    "for key in selected_articles_df.index:\n",
    "    tags = selected_articles_df.loc[key, \"Tags\"]\n",
    "    for tag in tags:\n",
    "        if tag.startswith(\"Board: \"):\n",
    "            if tag not in devices_tags:\n",
    "                devices_tags[tag] = []\n",
    "            devices_tags[tag].append(key)\n",
    "        elif tag.startswith(\"Task: \"):\n",
    "            if tag not in tasks_tags:\n",
    "                tasks_tags[tag] = []\n",
    "            tasks_tags[tag].append(key)\n",
    "        elif tag.startswith(\"Model: \"):\n",
    "            if tag not in models_tags:\n",
    "                models_tags[tag] = []\n",
    "            models_tags[tag].append(key)\n",
    "        elif tag.startswith(\"Implementation: \"):\n",
    "            if tag not in implementations_tags:\n",
    "                implementations_tags[tag] = []\n",
    "            implementations_tags[tag].append(key)\n",
    "        elif tag.startswith(\"Modality: \"):\n",
    "            if tag not in modalities_tags:\n",
    "                modalities_tags[tag] = []\n",
    "            modalities_tags[tag].append(key)\n",
    "        else:\n",
    "            if tag not in miscellaneoustags:\n",
    "                miscellaneoustags[tag] = []\n",
    "            miscellaneoustags[tag].append(key)\n",
    "\n",
    "# Split devices tags into 3 further dictionnaries: Family, model and board/evaluation kit\n",
    "devices_families = {}\n",
    "devices_models = {}\n",
    "devices_boards = {}\n",
    "for tag in devices_tags:\n",
    "    # Each tag is formatted like \"Board: family (model) {board/evaluation kit}\", sometimes there is no board/evaluation kit\n",
    "    # Example: \"Board: Zynq 7000 (Z7020) {PYNQ-Z1}\" or \"Board: Kintex US (KU115)\"\n",
    "    family = tag.split(\" (\")[0].split(\": \")[1]\n",
    "    model = tag.split(\" (\")[1].split(\")\")[0] if \"(\" in tag else None\n",
    "    board = tag.split(\"{\")[1].split(\"}\")[0] if \"{\" in tag else None\n",
    "    if family not in devices_families:\n",
    "        devices_families[family] = 0\n",
    "    devices_families[family] += len(devices_tags[tag])\n",
    "    if model not in devices_models:\n",
    "        devices_models[model] = 0\n",
    "    devices_models[model] += len(devices_tags[tag])\n",
    "    if board not in devices_boards:\n",
    "        devices_boards[board] = 0\n",
    "    devices_boards[board] += len(devices_tags[tag])\n",
    "\n",
    "# --- Print the number of articles for each tag ---\n",
    "print(\"Number of articles with the corresponding tags:\")\n",
    "print(\n",
    "    f\"{r}{get_total_in_dict_of_lists(devices_tags)}{e} boards, \"\n",
    "    f\"{r}{get_total_in_dict_of_lists(tasks_tags)}{e} tasks, \"\n",
    "    f\"{r}{get_total_in_dict_of_lists(models_tags)}{e} models, \"\n",
    "    f\"{r}{get_total_in_dict_of_lists(implementations_tags)}{e} implementations and \"\n",
    "    f\"{r}{get_total_in_dict_of_lists(modalities_tags)}{e} modalities\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n\\n\")\n",
    "\n",
    "# Statistics about Implementation means\n",
    "print(\n",
    "    f\"{r}{len(implementations_tags)}{e} different implementations, in total {g}{get_total_in_dict_of_lists(implementations_tags)}{e}:\"\n",
    ")\n",
    "for tag, keys in implementations_tags.items():\n",
    "    print(f' - {r}{len(keys):>3}{e} items for {b}\"{tag[16:]}\"{e}')\n",
    "\n",
    "# Statistics about the downstream Tasks\n",
    "print(\n",
    "    f\"{r}{len(tasks_tags)}{e} different tasks, in total {g}{get_total_in_dict_of_lists(tasks_tags)}{e}:\"\n",
    ")\n",
    "for tag, keys in tasks_tags.items():\n",
    "    print(f' - {r}{len(keys):>3}{e} items for {b}\"{tag[6:]}\"{e}')\n",
    "\n",
    "# Statistics about the Models\n",
    "print(\n",
    "    f\"{r}{len(models_tags)}{e} different models, in total {g}{get_total_in_dict_of_lists(models_tags)}{e}:\"\n",
    ")\n",
    "for tag, keys in models_tags.items():\n",
    "    print(f' - {r}{len(keys):>3}{e} items for {b}\"{tag[7:]}\"{e}')\n",
    "\n",
    "# Statistics about the Modalities\n",
    "print(\n",
    "    f\"{r}{len(modalities_tags)}{e} different modalities tags, in total {g}{get_total_in_dict_of_lists(modalities_tags)}{e}:\"\n",
    ")\n",
    "for tag, keys in modalities_tags.items():\n",
    "    print(f' - {r}{len(keys):>3}{e} items for {b}\"{tag}\"{e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'DOI': '10.1109/TIE.2017.2708028',\n",
      "          'ISSN': '1557-9948',\n",
      "          'abstractNote': 'The Fuzzy ARTMAP is a supervised learning method, '\n",
      "                          'providing high accuracy in many classifications. In '\n",
      "                          'this paper, we explore the role of hardware '\n",
      "                          'accelerators in remote sensing classification '\n",
      "                          'missions. We focus on the designing and '\n",
      "                          'implementing a massively parallel hardware '\n",
      "                          'architecture on a field-programmable gate array '\n",
      "                          \"(FPGA) of the performance phase's algorithm. The \"\n",
      "                          'implementation is mapped on Xilinx Virtex 6 '\n",
      "                          'XC6VLX240T FPGA chip for an embedded system using '\n",
      "                          'Xilinx ISE 14.5 software. Embedded blocks dedicated '\n",
      "                          'to digital signal processing (DSP) and blocks '\n",
      "                          'memories are used. DSP48E1 is part of Virtex-6 '\n",
      "                          'FPGAs devices. It boasts of increased capability '\n",
      "                          'over previous generations, and is highly '\n",
      "                          'customizable, a key feature of this primitive that '\n",
      "                          'has motivated and enabled the work presented in '\n",
      "                          'this paper. We illustrate the application of this '\n",
      "                          'methodology to the valuation of various schemes '\n",
      "                          'involving embedded elements. This paper also '\n",
      "                          'presents a summary of the performance cost with '\n",
      "                          'regard to the speed, power, and required '\n",
      "                          'computational resources.',\n",
      "          'accessDate': '2024-06-18T07:29:22Z',\n",
      "          'archive': '',\n",
      "          'archiveLocation': '',\n",
      "          'callNumber': '',\n",
      "          'collections': ['IQSG5XFZ', 'LWR4HAWY'],\n",
      "          'creators': [{'creatorType': 'author',\n",
      "                        'firstName': 'Réda',\n",
      "                        'lastName': 'Yahiaoui'},\n",
      "                       {'creatorType': 'author',\n",
      "                        'firstName': 'Farid',\n",
      "                        'lastName': 'Alilat'},\n",
      "                       {'creatorType': 'author',\n",
      "                        'firstName': 'Saliha',\n",
      "                        'lastName': 'Loumi'}],\n",
      "          'date': '2017-12',\n",
      "          'dateAdded': '2024-06-18T07:29:22Z',\n",
      "          'dateModified': '2024-07-08T07:19:14Z',\n",
      "          'extra': 'Conference Name: IEEE Transactions on Industrial '\n",
      "                   'Electronics',\n",
      "          'issue': '12',\n",
      "          'itemType': 'journalArticle',\n",
      "          'journalAbbreviation': '',\n",
      "          'key': 'H6JZ28QZ',\n",
      "          'language': '',\n",
      "          'libraryCatalog': 'IEEE Xplore',\n",
      "          'pages': '9487-9495',\n",
      "          'publicationTitle': 'IEEE Transactions on Industrial Electronics',\n",
      "          'relations': {},\n",
      "          'rights': '',\n",
      "          'series': '',\n",
      "          'seriesText': '',\n",
      "          'seriesTitle': '',\n",
      "          'shortTitle': 'Parallelization of Fuzzy ARTMAP Architecture on FPGA',\n",
      "          'tags': [{'tag': 'ALSAT-2A (4 bands: RGB + infrared)'},\n",
      "                   {'tag': 'Board: Virtext-6 (XC6VLX240T)'},\n",
      "                   {'tag': 'FPGA design'},\n",
      "                   {'tag': 'Implementation: RTL design'},\n",
      "                   {'tag': 'ML-FPGA review'},\n",
      "                   {'tag': 'Modality: MSI'},\n",
      "                   {'tag': 'Modality: RGB'},\n",
      "                   {'tag': 'Model: Fuzzy ARTMAP'},\n",
      "                   {'tag': 'Task: Pixel classification'},\n",
      "                   {'tag': 'UnRead'},\n",
      "                   {'tag': 'VHDL'}],\n",
      "          'title': 'Parallelization of Fuzzy ARTMAP Architecture on FPGA: '\n",
      "                   'Multispectral Classification of ALSAT-2A Images',\n",
      "          'url': 'https://ieeexplore.ieee.org/document/7934103',\n",
      "          'version': 7328,\n",
      "          'volume': '64'},\n",
      " 'key': 'H6JZ28QZ',\n",
      " 'library': {'id': 8968938,\n",
      "             'links': {'alternate': {'href': 'https://www.zotero.org/cedricleon',\n",
      "                                     'type': 'text/html'}},\n",
      "             'name': 'CedricLeon',\n",
      "             'type': 'user'},\n",
      " 'links': {'alternate': {'href': 'https://www.zotero.org/cedricleon/items/H6JZ28QZ',\n",
      "                         'type': 'text/html'},\n",
      "           'self': {'href': 'https://api.zotero.org/users/8968938/items/H6JZ28QZ',\n",
      "                    'type': 'application/json'}},\n",
      " 'meta': {'creatorSummary': 'Yahiaoui et al.',\n",
      "          'numChildren': 2,\n",
      "          'parsedDate': '2017-12'},\n",
      " 'version': 7328}\n",
      "{'data': {'DOI': '10.1007/978-3-030-00692-1_35',\n",
      "          'ISBN': '0302-9743',\n",
      "          'abstractNote': 'This paper presents an embedded video subsystem '\n",
      "                          'used to classify the terrain, based on an image '\n",
      "                          'from a camera located under the drone, for the '\n",
      "                          'purpose of an automatic landing system. Colour and '\n",
      "                          'texture features, as well as decision trees and '\n",
      "                          'support vector machine classifiers were analysed '\n",
      "                          'and evaluated. The algorithm was supported with a '\n",
      "                          'shadow detection module. It was evaluated on 100 '\n",
      "                          'test cases and achieved over 80% performance. The '\n",
      "                          'designed video system was implemented on two '\n",
      "                          'embedded platforms - a Zynq SoC (System on Chip - '\n",
      "                          'Field Programmable Gate Array + ARM processor '\n",
      "                          'system) and a Jetson GPU (Graphic Processing Unit + '\n",
      "                          'ARM processor system). The performance achieved on '\n",
      "                          'both architectures is compared and discussed.',\n",
      "          'accessDate': '',\n",
      "          'archive': '',\n",
      "          'archiveLocation': 'WOS:000614368800035',\n",
      "          'callNumber': '',\n",
      "          'collections': ['LWR4HAWY', 'LMA2GSBN'],\n",
      "          'conferenceName': 'COMPUTER VISION AND GRAPHICS ( ICCVG 2018)',\n",
      "          'creators': [{'creatorType': 'author',\n",
      "                        'firstName': 'P',\n",
      "                        'lastName': 'Fraczek'},\n",
      "                       {'creatorType': 'author',\n",
      "                        'firstName': 'A',\n",
      "                        'lastName': 'Mora'},\n",
      "                       {'creatorType': 'author',\n",
      "                        'firstName': 'T',\n",
      "                        'lastName': 'Kryjak'},\n",
      "                       {'creatorType': 'editor',\n",
      "                        'firstName': 'LJ',\n",
      "                        'lastName': 'Chmielewski'},\n",
      "                       {'creatorType': 'editor',\n",
      "                        'firstName': 'R',\n",
      "                        'lastName': 'Kozera'},\n",
      "                       {'creatorType': 'editor',\n",
      "                        'firstName': 'A',\n",
      "                        'lastName': 'Orlowski'},\n",
      "                       {'creatorType': 'editor',\n",
      "                        'firstName': 'K',\n",
      "                        'lastName': 'Wojciechowski'},\n",
      "                       {'creatorType': 'editor',\n",
      "                        'firstName': 'AM',\n",
      "                        'lastName': 'Bruckstein'},\n",
      "                       {'creatorType': 'editor',\n",
      "                        'firstName': 'N',\n",
      "                        'lastName': 'Petkov'}],\n",
      "          'date': '2018',\n",
      "          'dateAdded': '2024-07-02T13:05:49Z',\n",
      "          'dateModified': '2024-07-08T07:08:57Z',\n",
      "          'extra': '',\n",
      "          'itemType': 'conferencePaper',\n",
      "          'key': 'EGZ2UZY4',\n",
      "          'language': 'English',\n",
      "          'libraryCatalog': '',\n",
      "          'pages': '397-409',\n",
      "          'place': '',\n",
      "          'proceedingsTitle': 'AGH University of Krakow',\n",
      "          'publisher': '',\n",
      "          'relations': {},\n",
      "          'rights': '',\n",
      "          'series': '',\n",
      "          'shortTitle': '',\n",
      "          'tags': [{'tag': 'Board: Arty Z7 (Z7020)'},\n",
      "                   {'tag': 'FPGA'},\n",
      "                   {'tag': 'Implementation: RTL design'},\n",
      "                   {'tag': 'ML-FPGA review'},\n",
      "                   {'tag': 'Mix ML-domain algorithms'},\n",
      "                   {'tag': 'Modality: RGB'},\n",
      "                   {'tag': 'Model: Decision Trees (DT)'},\n",
      "                   {'tag': 'Model: SVM'},\n",
      "                   {'tag': 'Outside scope of review'},\n",
      "                   {'tag': 'Safe landing site detection'},\n",
      "                   {'tag': 'Task: Landing site detection'},\n",
      "                   {'tag': 'Task: Pixel classification'},\n",
      "                   {'tag': 'UAV'},\n",
      "                   {'tag': 'Verilog'}],\n",
      "          'title': 'Embedded Vision System for Automated Drone Landing Site '\n",
      "                   'Detection',\n",
      "          'url': '',\n",
      "          'version': 7308,\n",
      "          'volume': '11114'},\n",
      " 'key': 'EGZ2UZY4',\n",
      " 'library': {'id': 8968938,\n",
      "             'links': {'alternate': {'href': 'https://www.zotero.org/cedricleon',\n",
      "                                     'type': 'text/html'}},\n",
      "             'name': 'CedricLeon',\n",
      "             'type': 'user'},\n",
      " 'links': {'alternate': {'href': 'https://www.zotero.org/cedricleon/items/EGZ2UZY4',\n",
      "                         'type': 'text/html'},\n",
      "           'self': {'href': 'https://api.zotero.org/users/8968938/items/EGZ2UZY4',\n",
      "                    'type': 'application/json'}},\n",
      " 'meta': {'creatorSummary': 'Fraczek et al.',\n",
      "          'numChildren': 1,\n",
      "          'parsedDate': '2018'},\n",
      " 'version': 7308}\n"
     ]
    }
   ],
   "source": [
    "pprint(zot.item(articles_selected_for_review[0]))\n",
    "pprint(zot.item(articles_selected_for_review[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mess",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
